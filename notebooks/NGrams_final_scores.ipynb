{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "from collections import Counter\n",
    "from collections import namedtuple\n",
    "import math\n",
    "import traceback\n",
    "import pandas\n",
    "\n",
    "Triple = namedtuple(\"Triple\", [\"src\", \"dest\"])\n",
    "DATA_DIR=\"/root/data/allen-ai-challenge/final_ngrams\"\n",
    "OUT_DIR=\"/root/data/allen-ai-challenge/final_ngrams/scores\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TripletStorage(object):\n",
    "\n",
    "    def __init__(self, file=None):\n",
    "        self.notype = Counter()\n",
    "        self.tokens = Counter()\n",
    "\n",
    "        debug_cnt = 0\n",
    "        self.file = file\n",
    "\n",
    "        if file is not None:\n",
    "            for line in open(file):\n",
    "                try:\n",
    "                    if len(line.split('\\t')) == 3:\n",
    "                        src, dest, cnt = line.split('\\t')\n",
    "                        \n",
    "                        triple = Triple(src=src, dest=dest)\n",
    "                        self.fill_one(triple, int(cnt))\n",
    "\n",
    "                        if debug_cnt % 1000000 == 0:\n",
    "                            print \"Read %d triplets\" % debug_cnt\n",
    "\n",
    "                        debug_cnt += 1\n",
    "                        \n",
    "                except:\n",
    "                    traceback.print_exc()\n",
    "\n",
    "    def fill_one(self, triple, cnt):\n",
    "        if not isinstance(triple, Triple):\n",
    "            raise ValueError\n",
    "\n",
    "        self.notype[(triple.src, triple.dest)] += cnt\n",
    "        self.tokens[triple.src] += cnt\n",
    "        self.tokens[triple.dest] += cnt\n",
    "        \n",
    "def score_norel(storage, src, dest, normalization=\"none\"):\n",
    "    score = max(storage.notype[(src, dest)], storage.notype[(dest, src)])\n",
    "\n",
    "    if score == 0:\n",
    "        return 0\n",
    "\n",
    "    if normalization == \"none\":\n",
    "        return score\n",
    "    elif normalization == \"left\":\n",
    "        return float(score)/math.log(storage.tokens[src])\n",
    "    elif normalization == \"right\":\n",
    "        return float(score)/math.log(storage.tokens[dest])\n",
    "    elif normalization == \"both\":\n",
    "        return float(score)/math.log(storage.tokens[src]*storage.tokens[dest])\n",
    "    else:\n",
    "        raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngrams_2_2 = TripletStorage(os.path.join(DATA_DIR, \"ngrams_2_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngrams_1_2 = TripletStorage(os.path.join(DATA_DIR, \"ngrams_1_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngrams_1_3 = TripletStorage(os.path.join(DATA_DIR, \"ngrams_1_3.good\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngrams_2_3 = TripletStorage(os.path.join(DATA_DIR, \"ngrams_2_3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "storage_storage = {\n",
    "    (2,2) : ngrams_2_2,\n",
    "    (1,3) : ngrams_1_3,\n",
    "    (1,2) : ngrams_1_2,\n",
    "    (2,3) : ngrams_2_3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_score_nonlp(q, ans, first_ngram_size=2, second_ngram_size=2, topN=5, normalization=\"both\"):\n",
    "    \n",
    "    scores = []\n",
    "\n",
    "    def _chunks(llist, size):\n",
    "        for i in range(0, len(llist) - size + 1):\n",
    "            yield llist[i:i+size]\n",
    "\n",
    "    tokens_q = q.split()\n",
    "    tokens_ans = ans.split()\n",
    "\n",
    "\n",
    "    for q_ngram in _chunks(tokens_q, first_ngram_size):\n",
    "        for ans_ngram in _chunks(tokens_ans, second_ngram_size):\n",
    "            score = score_norel(storage_storage[(first_ngram_size, second_ngram_size)], \" \".join(q_ngram), \" \".join(ans_ngram), \n",
    "                                normalization=normalization)\n",
    "            scores.append(score)\n",
    "    \n",
    "    for q_ngram in _chunks(tokens_q, second_ngram_size):\n",
    "        for ans_ngram in _chunks(tokens_ans, first_ngram_size):\n",
    "            score = score_norel(storage_storage[(first_ngram_size, second_ngram_size)], \" \".join(q_ngram), \" \".join(ans_ngram), \n",
    "                                normalization=normalization)\n",
    "            scores.append(score)\n",
    "\n",
    "    scores = sorted(scores, reverse=True)\n",
    "    if len(scores) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return float(sum(scores[:topN]))/min(topN, len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_df(is_train, first_ngram_size, second_ngram_size):\n",
    "    total_cnt = 0\n",
    "    correct_cnt = 0\n",
    "    equal_cnt = 0\n",
    "\n",
    "    all_scores = []\n",
    "    if is_train:\n",
    "        inpath = \"training_set_cleaned.tsv\"\n",
    "        prefix = \"training\"\n",
    "    else:\n",
    "        inpath = \"validation_set_cleaned.tsv\"\n",
    "        prefix = \"validation\"\n",
    "        \n",
    "    for line in open(os.path.join(\"/root/data/allen-ai-challenge/\", inpath)):\n",
    "        if is_train:\n",
    "            _id, q, correct_ans, a, b, c, d = line.split('\\t')\n",
    "        else:\n",
    "            _id, q, a, b, c, d = line.split('\\t')\n",
    "            correct_ans = None\n",
    "\n",
    "        scores = [one_score_nonlp(q.decode(\"utf-8\"), x.decode(\"utf-8\"), \n",
    "                                  first_ngram_size=first_ngram_size, \n",
    "                                  second_ngram_size=second_ngram_size, \n",
    "                                  topN=20,normalization=\"both\") for x in [a,b,c,d]]\n",
    "\n",
    "        if len(numpy.unique(scores)) == 1:\n",
    "                equal_cnt += 1\n",
    "        else:\n",
    "            picked = [\"A\",\"B\",\"C\",\"D\"][numpy.argmax(scores)]\n",
    "\n",
    "            if picked == correct_ans:\n",
    "                correct_cnt += 1\n",
    "\n",
    "            total_cnt += 1\n",
    "            all_scores.append([_id] + scores)\n",
    "\n",
    "            if total_cnt % 100 == 0:\n",
    "                print \"====%f====\" % (float(correct_cnt)/total_cnt)\n",
    "\n",
    "    print \"precision:%f\" % (float(correct_cnt)/total_cnt)\n",
    "    print \"total: %d, skipped: %d\" % (total_cnt, equal_cnt)\n",
    "    \n",
    "    df = pandas.DataFrame.from_records(all_scores)\n",
    "    df.to_csv(os.path.join(OUT_DIR, \"%s_ngrams_%d_%d.csv\" % (prefix, first_ngram_size, second_ngram_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====0.540000====\n",
      "====0.510000====\n",
      "====0.486667====\n",
      "====0.457500====\n",
      "====0.442000====\n",
      "precision:0.452763\n",
      "total: 561, skipped: 1939\n",
      "====0.000000====\n",
      "====0.000000====\n",
      "====0.000000====\n",
      "precision:0.000000\n",
      "total: 385, skipped: 7747\n"
     ]
    }
   ],
   "source": [
    "make_df(True, 2, 3)\n",
    "make_df(False, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_df(True, 2, 2)\n",
    "make_df(False, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_df(True, 1, 2)\n",
    "make_df(False, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_df(True, 1, 3)\n",
    "make_df(False, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_dfs(*dfs):\n",
    "    for df in dfs:\n",
    "        df.fillna(0)\n",
    "    \n",
    "    res_df = dfs[0]\n",
    "    for i in range(1, len(dfs)):\n",
    "        print res_df\n",
    "        res_df = res_df.merge(dfs[i], how=\"outer\", left_index=True, right_index=True)\n",
    "        \n",
    "        def appl(serie):\n",
    "            return pandas.Series({\n",
    "                \"A\": str(serie[\"A_x\"]) + \";\" + str(serie[\"A_y\"]),\n",
    "                \"B\": str(serie[\"B_x\"]) + \";\" + str(serie[\"B_y\"]),\n",
    "                \"C\": str(serie[\"C_x\"]) + \";\" + str(serie[\"C_y\"]),\n",
    "                \"D\": str(serie[\"D_x\"]) + \";\" + str(serie[\"D_y\"]),\n",
    "            })\n",
    "        \n",
    "        res_df = res_df.fillna(0).apply(appl, axis=1)\n",
    "            \n",
    "        \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_dfs = []\n",
    "validation_dfs = []\n",
    "\n",
    "for i in range(1,4):\n",
    "    for j in range(i,4):\n",
    "        try:\n",
    "            tr_df = pandas.DataFrame.from_csv(os.path.join(DATA_DIR, \"scores/training_ngrams_%d_%d.csv\" % (i,j)))\n",
    "            tr_df.columns = [\"id\",\"A\",\"B\",\"C\",\"D\"]\n",
    "            tr_df.set_index(\"id\", inplace=True)\n",
    "            training_dfs.append(tr_df)\n",
    "            \n",
    "            val_df = pandas.DataFrame.from_csv(os.path.join(DATA_DIR, \"scores/validation_ngrams_%d_%d.csv\" % (i,j)))\n",
    "            val_df.columns = [\"id\",\"A\",\"B\",\"C\",\"D\"]\n",
    "            val_df.set_index(\"id\", inplace=True)\n",
    "            validation_dfs.append(val_df)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged = merge_dfs(*validation_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged.to_csv(os.path.join(OUT_DIR,\"validation_merged_ngrams.tsv\"), sep='\\t', header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
