{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import re\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.1\n"
     ]
    }
   ],
   "source": [
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = join(os.environ['HOME'], \"data/allen-ai-challenge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WIKI_DIR = join(DATA_DIR, \"parsed_wiki_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_SET = join(DATA_DIR, \"training_set.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_text(t):\n",
    "    s = re.sub(r'[^\\w\\s]', '', t)\n",
    "    r = s.lower().split()\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iter_text(directory):\n",
    "    for fname in os.listdir(directory):\n",
    "        with open(os.path.join(directory, fname), encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            for l in f:\n",
    "                r = parse_text(l)\n",
    "                if r != []:\n",
    "                    yield r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['39', 'is', 'a', 'song', 'by', 'british', 'rock', 'band', 'queen', 'composed', 'by', 'lead', 'guitarist', 'brian', 'may', 'it', 'is', 'the', 'fifth', 'track', 'on', 'their', 'fourth', 'studio', 'album', 'a', 'night', 'at', 'the', 'opera']\n",
      "['the', 'song', 'relates', 'the', 'tale', 'of', 'a', 'group', 'of', 'space', 'explorers', 'who', 'embark', 'on', 'what', 'is', 'from', 'their', 'perspective', 'a', 'yearlong', 'voyage', 'upon', 'their', 'return', 'however', 'they', 'realise', 'that', 'a', 'hundred', 'years', 'have', 'passed', 'because', 'of', 'the', 'time', 'dilation', 'effect', 'in', 'einsteins', 'special', 'theory', 'of', 'relativity', 'and', 'the', 'loved', 'ones', 'they', 'left', 'behind', 'are', 'now', 'all', 'dead', 'or', 'aged']\n",
      "['the', 'line', 'your', 'mothers', 'eyes', 'from', 'your', 'eyes', 'cry', 'to', 'me', 'refers', 'to', 'his', 'sense', 'of', 'loss', 'at', 'seeing', 'his', 'daughters', 'eyes', 'in', 'his', 'aged', 'granddaughters', 'eyes']\n",
      "['the', 'song', 'was', 'also', 'the', 'bside', 'to', 'youre', 'my', 'best', 'friend']\n",
      "['if', 'you', 'add', 'all', 'previous', 'queen', 'songs', 'on', 'the', 'first', 'three', 'albums', 'not', 'including', 'nonalbum', 'songs', 'and', 'the', 'first', 'few', 'on', 'this', 'album', '39', 'is', 'the', '39th', 'queen', 'song', 'in', 'order', 'to', 'be', 'released']\n",
      "['recording']\n",
      "['may', 'had', 'asked', 'bassist', 'john', 'deacon', 'to', 'play', 'double', 'bass', 'as', 'a', 'joke', 'but', 'a', 'couple', 'of', 'days', 'later', 'he', 'found', 'deacon', 'in', 'the', 'studio', 'with', 'the', 'instrument', 'and', 'he', 'had', 'already', 'learned', 'to', 'play', 'it']\n",
      "['since', 'queen', 'had', 'named', 'their', 'albums', 'a', 'night', 'at', 'the', 'opera', 'and', 'a', 'day', 'at', 'the', 'races', 'after', 'two', 'of', 'the', 'marx', 'brothers', 'most', 'popular', 'films', 'surviving', 'brother', 'groucho', 'marx', 'invited', 'queen', 'to', 'visit', 'him', 'at', 'his', 'los', 'angeles', 'home', 'in', 'march', '1977', 'five', 'months', 'before', 'he', 'died', 'the', 'band', 'thanked', 'him', 'and', 'performed', '39', 'a', 'cappella']\n",
      "['live', 'performances']\n",
      "['the', 'song', 'was', 'first', 'performed', 'in', 'edinburgh', 'in', 'september', '1976', 'and', 'remained', 'in', 'setlists', 'until', 'december', '1979', 'although', 'the', 'song', 'was', 'briefly', 'performed', 'in', '1984', 'instead', 'of', 'may', 'singing', 'the', 'lead', 'vocals', 'mercury', 'does']\n",
      "['george', 'michael', 'performed', '39', 'at', 'the', 'freddie', 'mercury', 'tribute', 'concert', 'in', 'april', '1992', 'michael', 'cited', 'this', 'song', 'as', 'his', 'favourite', 'queen', 'song', 'claiming', 'he', 'used', 'to', 'busk', 'it', 'on', 'the', 'london', 'underground']\n",
      "['recently', 'queen', 'have', 'included', 'the', 'song', 'on', 'the', 'setlists', 'of', 'their', 'queen', 'adam', 'lambert', 'tours', 'in', '2012', '20142015', 'featuring', 'adam', 'lambert', 'both', 'queen', 'paul', 'rodgers', 'tours', 'which', 'were', 'queen', 'paul', 'rodgers', 'tour', 'rock', 'the', 'cosmos', 'featuring', 'paul', 'rodgers', 'as', 'on', 'the', 'album', 'it', 'is', 'sung', 'by', 'may']\n"
     ]
    }
   ],
   "source": [
    "for i, l in enumerate(iter_text(WIKI_DIR)):\n",
    "    print(l)\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sentences(object):\n",
    "    \n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for text in iter_text(self.directory):\n",
    "            yield text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = Sentences(WIKI_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 2s, sys: 49.8 s, total: 13min 52s\n",
      "Wall time: 7min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_model = gensim.models.Word2Vec(sentences, workers=multiprocessing.cpu_count(),\n",
    "                                    size=40, iter=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95708"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dwarfs', 0.8680418729782104),\n",
       " ('jupiterlike', 0.8368364572525024),\n",
       " ('starforming', 0.8171519637107849),\n",
       " ('mainsequence', 0.8158100843429565),\n",
       " ('stars', 0.8151733875274658),\n",
       " ('subbrown', 0.8139293193817139),\n",
       " ('sunlike', 0.812651515007019),\n",
       " ('supergiant', 0.8106808662414551),\n",
       " ('plutoids', 0.80396568775177),\n",
       " ('galaxies', 0.8015128374099731)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_model.most_similar(\"dwarf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quantify_text(t, model):\n",
    "    words = parse_text(t)\n",
    "    emb = [word_model[w] for w in words if w in word_model.vocab and len(w) > 0]\n",
    "    if emb != []:\n",
    "        return np.mean(emb, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import matutils\n",
    "def similarity(v1, v2):\n",
    "    return np.dot(matutils.unitvec(np.array(v1)), matutils.unitvec(np.array(v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def range_answers(q, answers, models):\n",
    "    scores = []\n",
    "    for model in models:\n",
    "        question = quantify_text(q, model)\n",
    "        if (question == 0).all():\n",
    "            return None\n",
    "        ps = Counter()\n",
    "        scores_model = []\n",
    "        for a in answers:\n",
    "            a_q = quantify_text(a, model)\n",
    "            if (a_q == 0).all():\n",
    "                scores_model.append(0) \n",
    "            else:\n",
    "                si = similarity(question, a_q)\n",
    "                scores_model.append(si)\n",
    "        scores.append(scores_model)\n",
    "    return np.mean(scores, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sperm that contains alleles HqT fuses with an egg that contains alleles hqt. Which of the following genotypes will form in the offspring? HHqqTt HhQqTt Hhqqtt HhqqTt\n"
     ]
    }
   ],
   "source": [
    "tries = []\n",
    "with open(TRAIN_SET) as f:\n",
    "    next(f)\n",
    "    for i, l in enumerate(f):\n",
    "        [qid, q, r, aa, ab, ac, ad] = l.strip().split(\"\\t\")\n",
    "        scores = range_answers(q, [aa, ab, ac, ad],\n",
    "                               [word_model])\n",
    "        no_scores = (scores == 0).all()\n",
    "        if not no_scores:\n",
    "            guess = \"ABCD\"[np.argmax(scores)]\n",
    "        else:\n",
    "            print(q, aa, ab, ac, ad)\n",
    "        tries.append(1 if guess == r else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3236"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
