{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import re\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import codecs\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english') + '. , ! ? !? ?! ... ; : - â€”'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.4\n"
     ]
    }
   ],
   "source": [
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.models.word2vec.FAST_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = join(os.environ['HOME'], \"data/allen-ai-challenge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WIKI_DIR = join(DATA_DIR, \"parsed_wiki_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_SET = join(DATA_DIR, \"training_set.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_text(t):\n",
    "    s = re.sub(r'[^\\w\\s]', '', t)\n",
    "    words = [w for w in nltk.word_tokenize(s.lower()) if w not in stopwords]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'book']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_text(\"test a book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iter_text(directory):\n",
    "    for fname in os.listdir(directory):\n",
    "        with codecs.open(os.path.join(directory, fname), encoding=\"utf-8\") as f:\n",
    "            for l in f:\n",
    "                r = parse_text(l)\n",
    "                if r != []:\n",
    "                    yield r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'churchill', u'inuit', u'kuugjuaq', u'town', u'northern', u'manitoba', u'canada', u'west', u'shore', u'hudson', u'bay', u'roughly', u'110', u'kilometres', u'manitobanunavut', u'border', u'famous', u'many', u'polar', u'bears', u'move', u'toward', u'shore', u'inland', u'autumn', u'leading', u'nickname', u'polar', u'bear', u'capital', u'world', u'helped', u'growing', u'tourism', u'industry']\n",
      "[u'geographyedit']\n",
      "[u'churchill', u'located', u'along', u'hudson', u'bay', u'58th', u'parallel', u'north', u'far', u'canadian', u'populated', u'areas', u'located', u'churchill', u'located', u'far', u'towns', u'cities', u'thompson', u'good', u'bit', u'south', u'closest', u'larger', u'settlement', u'province', u'capital', u'winnipeg', u'distant', u'even', u'airplane', u'nine', u'degrees', u'south', u'bit', u'west']\n",
      "[u'historyedit']\n"
     ]
    }
   ],
   "source": [
    "for i, l in enumerate(iter_text(WIKI_DIR)):\n",
    "    print(l)\n",
    "    if i > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sentences(object):\n",
    "    \n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for text in iter_text(self.directory):\n",
    "            yield text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = Sentences(WIKI_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "word_model = gensim.models.Word2Vec(sentences, workers=12,\n",
    "                                    size=8, iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(word_model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_model.most_similar(\"dwarf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quantify_text(t, model):\n",
    "    words = parse_text(t)\n",
    "    emb = [word_model[w] for w in words if w in word_model.vocab and len(w) > 0]\n",
    "    if emb != []:\n",
    "        return np.mean(emb, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import matutils\n",
    "def similarity(v1, v2):\n",
    "    return np.dot(matutils.unitvec(np.array(v1)), matutils.unitvec(np.array(v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def range_answers(q, answers, models):\n",
    "    scores = []\n",
    "    for model in models:\n",
    "        question = quantify_text(q, model)\n",
    "        if (question == 0).all():\n",
    "            return None\n",
    "        ps = Counter()\n",
    "        scores_model = []\n",
    "        for a in answers:\n",
    "            a_q = quantify_text(a, model)\n",
    "            if (a_q == 0).all():\n",
    "                scores_model.append(0) \n",
    "            else:\n",
    "                si = similarity(question, a_q)\n",
    "                scores_model.append(si)\n",
    "        scores.append(scores_model)\n",
    "    return np.mean(scores, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sperm that contains alleles HqT fuses with an egg that contains alleles hqt. Which of the following genotypes will form in the offspring? HHqqTt HhQqTt Hhqqtt HhqqTt\n"
     ]
    }
   ],
   "source": [
    "tries = []\n",
    "with open(TRAIN_SET) as f:\n",
    "    next(f)\n",
    "    for i, l in enumerate(f):\n",
    "        [qid, q, r, aa, ab, ac, ad] = l.strip().split(\"\\t\")\n",
    "        scores = range_answers(q, [aa, ab, ac, ad],\n",
    "                               [word_model])\n",
    "        no_scores = (scores == 0).all()\n",
    "        if not no_scores:\n",
    "            guess = \"ABCD\"[np.argmax(scores)]\n",
    "        else:\n",
    "            print(q, aa, ab, ac, ad)\n",
    "        tries.append(1 if guess == r else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3236"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
