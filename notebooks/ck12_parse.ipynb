{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import telepot\n",
    "def telegram_notify(msg):\n",
    "    token = \"178350795:AAFG7yae2SSt52GLek2bKS43oK7BaywWxRw\"\n",
    "    bot = telepot.Bot(token)\n",
    "    b = bot.getMe()\n",
    "    response = bot.getUpdates()\n",
    "    bot.sendMessage(31747780, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Pavel'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"HOME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "telegram_notify(\"wop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:scrapy.utils.log:Scrapy 1.0.4 started (bot: scrapybot)\n",
      "INFO: Scrapy 1.0.4 started (bot: scrapybot)\n",
      "2016-01-16 13:44:56 [scrapy] INFO: Scrapy 1.0.4 started (bot: scrapybot)\n",
      "INFO:scrapy.utils.log:Optional features available: ssl, http11, boto\n",
      "INFO: Optional features available: ssl, http11, boto\n",
      "2016-01-16 13:44:56 [scrapy] INFO: Optional features available: ssl, http11, boto\n",
      "INFO:scrapy.utils.log:Overridden settings: {}\n",
      "INFO: Overridden settings: {}\n",
      "2016-01-16 13:44:56 [scrapy] INFO: Overridden settings: {}\n",
      "INFO:scrapy.middleware:Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState\n",
      "INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState\n",
      "2016-01-16 13:44:56 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState\n",
      "INFO:scrapy.middleware:Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats\n",
      "INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats\n",
      "2016-01-16 13:44:57 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats\n",
      "INFO:scrapy.middleware:Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware\n",
      "INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware\n",
      "2016-01-16 13:44:57 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware\n",
      "INFO:scrapy.middleware:Enabled item pipelines: \n",
      "INFO: Enabled item pipelines: \n",
      "2016-01-16 13:44:57 [scrapy] INFO: Enabled item pipelines: \n",
      "INFO:scrapy.core.engine:Spider opened\n",
      "INFO: Spider opened\n",
      "2016-01-16 13:44:57 [scrapy] INFO: Spider opened\n",
      "INFO:scrapy.extensions.logstats:Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2016-01-16 13:44:57 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "DEBUG:scrapy.telnet:Telnet console listening on 127.0.0.1:6023\n",
      "DEBUG: Telnet console listening on 127.0.0.1:6023\n",
      "2016-01-16 13:44:57 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023\n",
      "DEBUG:scrapy.downloadermiddlewares.redirect:Redirecting (302) to <GET https://ya.ru/> from <GET http://ya.ru>\n",
      "DEBUG: Redirecting (302) to <GET https://ya.ru/> from <GET http://ya.ru>\n",
      "2016-01-16 13:44:57 [scrapy] DEBUG: Redirecting (302) to <GET https://ya.ru/> from <GET http://ya.ru>\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET https://ya.ru/> (referer: None)\n",
      "DEBUG: Crawled (200) <GET https://ya.ru/> (referer: None)\n",
      "2016-01-16 13:44:57 [scrapy] DEBUG: Crawled (200) <GET https://ya.ru/> (referer: None)\n",
      "INFO:ck12:A response from https://ya.ru/ just arrived!\n",
      "INFO: A response from https://ya.ru/ just arrived!\n",
      "2016-01-16 13:44:57 [ck12] INFO: A response from https://ya.ru/ just arrived!\n",
      "INFO:scrapy.core.engine:Closing spider (finished)\n",
      "INFO: Closing spider (finished)\n",
      "2016-01-16 13:44:57 [scrapy] INFO: Closing spider (finished)\n",
      "INFO:scrapy.statscollectors:Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 444,\n",
      " 'downloader/request_count': 2,\n",
      " 'downloader/request_method_count/GET': 2,\n",
      " 'downloader/response_bytes': 5134,\n",
      " 'downloader/response_count': 2,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'downloader/response_status_count/302': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2016, 1, 16, 10, 44, 57, 479587),\n",
      " 'log_count/DEBUG': 3,\n",
      " 'log_count/INFO': 8,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 2,\n",
      " 'scheduler/dequeued/memory': 2,\n",
      " 'scheduler/enqueued': 2,\n",
      " 'scheduler/enqueued/memory': 2,\n",
      " 'start_time': datetime.datetime(2016, 1, 16, 10, 44, 57, 109087)}\n",
      "INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 444,\n",
      " 'downloader/request_count': 2,\n",
      " 'downloader/request_method_count/GET': 2,\n",
      " 'downloader/response_bytes': 5134,\n",
      " 'downloader/response_count': 2,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'downloader/response_status_count/302': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2016, 1, 16, 10, 44, 57, 479587),\n",
      " 'log_count/DEBUG': 3,\n",
      " 'log_count/INFO': 8,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 2,\n",
      " 'scheduler/dequeued/memory': 2,\n",
      " 'scheduler/enqueued': 2,\n",
      " 'scheduler/enqueued/memory': 2,\n",
      " 'start_time': datetime.datetime(2016, 1, 16, 10, 44, 57, 109087)}\n",
      "2016-01-16 13:44:57 [scrapy] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 444,\n",
      " 'downloader/request_count': 2,\n",
      " 'downloader/request_method_count/GET': 2,\n",
      " 'downloader/response_bytes': 5134,\n",
      " 'downloader/response_count': 2,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'downloader/response_status_count/302': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2016, 1, 16, 10, 44, 57, 479587),\n",
      " 'log_count/DEBUG': 3,\n",
      " 'log_count/INFO': 8,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 2,\n",
      " 'scheduler/dequeued/memory': 2,\n",
      " 'scheduler/enqueued': 2,\n",
      " 'scheduler/enqueued/memory': 2,\n",
      " 'start_time': datetime.datetime(2016, 1, 16, 10, 44, 57, 109087)}\n",
      "INFO:scrapy.core.engine:Spider closed (finished)\n",
      "INFO: Spider closed (finished)\n",
      "2016-01-16 13:44:57 [scrapy] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.utils.log import configure_logging\n",
    "from twisted.internet import reactor\n",
    "\n",
    "class MySpider(scrapy.Spider):\n",
    "    name = 'ck12'\n",
    "    allowed_domains = ['ya.ru']\n",
    "    start_urls = [\n",
    "        'http://ya.ru',\n",
    "    ]\n",
    "    custom_settings = {'DOWNLOAD_HANDLERS': {'s3': None}}\n",
    "\n",
    "    def parse(self, response):\n",
    "        self.logger.info('A response from %s just arrived!', response.url)\n",
    "\n",
    "configure_logging({'LOG_FORMAT': '%(levelname)s: %(message)s'})\n",
    "crawler = CrawlerProcess()\n",
    "\n",
    "crawler.crawl(MySpider)\n",
    "crawler.start()\n",
    "# d.addBoth(lambda _: reactor.stop())\n",
    "# reactor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crawler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
