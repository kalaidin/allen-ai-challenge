{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка работы Reptil и его параметры, фичи\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import os, sys\n",
    "from os.path import join\n",
    "import json\n",
    "from codecs import open\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/cuda-7.5/lib64:/root/reps/AdaGram.jl/lib'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"LD_LIBRARY_PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdaGramModel(object):\n",
    "    \n",
    "    def __init__(self, path_to_model, path_to_dict):\n",
    "        self.j = julia.Julia()\n",
    "        self.j.eval(\"using AdaGram\")\n",
    "        self.j.eval('vm, dict = load_model(\"%s\")' % path_to_model)\n",
    "        self.d = self.j.eval('size(vm.In, 1)') # size of word vectors\n",
    "        self.m = self.j.eval('size(vm.In, 2)') # number of context \n",
    "        self.n = self.j.eval('size(vm.In, 3)') # number of vectors\n",
    "        # TODO: AdaGram.Dictionary -> Python dict()?\n",
    "        self.dictionary = dict()\n",
    "        with open(path_to_dict) as f:\n",
    "            next(f) # skip strange empty token\n",
    "            for l in f:\n",
    "                r = l.strip().split()\n",
    "                self.dictionary[r[0]] = int(r[1])\n",
    "    \n",
    "    def expected_pi(self, word):\n",
    "        return self.j.eval('expected_pi(vm, dict.word2id[\"%s\"])' % word)\n",
    "    \n",
    "    def disambiguate(self, word, context):\n",
    "        return self.j.eval('disambiguate(vm, dict, \"%s\", split(\"%s\"))' % (word, context))\n",
    "    \n",
    "    def vec(self, word, pi):\n",
    "        assert pi + 1 <= self.m, \"n of prototypes mismatch\"\n",
    "        return self.j.eval('vec(vm, dict, \"%s\", %d)' % (word, pi + 1))\n",
    "    \n",
    "    def nearest_neighbors(self, word, pi):\n",
    "        return self.j.eval('nearest_neighbors(vm, dict, \"%s\", %d)' % (word, pi + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ROOT_DATA = join(os.environ[\"HOME\"], \"data/allen-ai-challenge\")\n",
    "TRAINING_CLEANED = join(ROOT_DATA, \"training_set_cleaned.tsv\")\n",
    "VALIDATION_CLEANED = join(ROOT_DATA, \"validation_set_cleaned.tsv\")\n",
    "MERGED = join(ROOT_DATA, \"corpus_paragraph_roman_2_short150-100.txt\")\n",
    "REPTIL_TRAIN_FEATURES = join(ROOT_DATA, \"training_set_reptil_features.tsv\")\n",
    "REPTIL_VALIDATION_FEATURES = join(ROOT_DATA, \"validation_set_reptil_features.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ADAGRAM_MODEL = join(ROOT_DATA, \"adam.model\")\n",
    "ADAGRAM_DICT = join(ROOT_DATA, \"adam.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "am = AdaGramModel(ADAGRAM_MODEL, ADAGRAM_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%sh\n",
    "# /root/reps/AdaGram.jl/utils/dictionary.sh /root/data/allen-ai-challenge/corpus_paragraph_unstable_short150-100.txt /root/data/allen-ai-challenge/adam.dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#corpus_paragraph_unstable_short150-100.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sh train.sh --min-freq 20 --window 5 --workers 40 --epochs 5 --dim 300 --alpha 0.1 /root/data/allen-ai-challenge/corpus_paragraph_unstable_short150-100.txt /root/data/allen-ai-challenge/adam.dict /root/data/allen-ai-challenge/adam.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# %%sh\n",
    "# /root/reps/AdaGram.jl/train.sh --min-freq 5 --window 5 --workers 47 --epochs 10 --dim 300 --alpha 0.15 /root/data/allen-ai-challenge/merged_corpus.txt /root/data/allen-ai-challenge/adam.dict /root/data/allen-ai-challenge/adam.model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_dict(t):\n",
    "    return [w for w in t.split() if w in am.dictionary and am.dictionary[w] >= 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sent_to_vec(sent, context):\n",
    "    v = np.zeros((N,), dtype='float32')\n",
    "    fc = filter_dict(context)\n",
    "    fs = filter_dict(sent)\n",
    "    if not fs:\n",
    "        return v\n",
    "    c = 0\n",
    "    for w in fs:\n",
    "        fc_cut = fc\n",
    "        # fc_cut.remove(w) # not helping\n",
    "        pi = am.disambiguate(w, \" \".join(fc_cut)).argmax()\n",
    "        vv = am.vec(w, pi)\n",
    "        v += vv\n",
    "        c += 1\n",
    "    return v / c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 1s, sys: 1.99 s, total: 1min 3s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tries = []\n",
    "with open(TRAINING_CLEANED, encoding=\"utf-8\") as f:\n",
    "    for i, l in enumerate(f):\n",
    "        [qid, q, r, aa, ab, ac, ad] = l.strip().split(\"\\t\")\n",
    "        vq = sent_to_vec(q, q)\n",
    "        va = sent_to_vec(aa, q + \" \" + aa)\n",
    "        vb = sent_to_vec(ab, q + \" \" + ab)\n",
    "        vc = sent_to_vec(ac, q + \" \" + ac)\n",
    "        vd = sent_to_vec(ad, q + \" \" + ad)\n",
    "#         va = sent_to_vec(aa, q)\n",
    "#         vb = sent_to_vec(ab, q)\n",
    "#         vc = sent_to_vec(ac, q)\n",
    "#         vd = sent_to_vec(ad, q)        \n",
    "        scores = [np.dot(x, vq) for x in [va, vb, vc, vd]]\n",
    "        g = \"ABCD\"[np.argmax(scores)]\n",
    "        tries.append(1 if g == r else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42520000000000002"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reptil features\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 158 ms, total: 1min 2s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(REPTIL_TRAIN_FEATURES, \"w\") as fo:\n",
    "    with open(TRAINING_CLEANED, encoding=\"utf-8\") as f:\n",
    "        for i, l in enumerate(f):\n",
    "            [qid, q, r, aa, ab, ac, ad] = l.strip().split(\"\\t\")\n",
    "            vq = sent_to_vec(q, q)\n",
    "            va = sent_to_vec(aa, q + \" \" + aa)\n",
    "            vb = sent_to_vec(ab, q + \" \" + ab)\n",
    "            vc = sent_to_vec(ac, q + \" \" + ac)\n",
    "            vd = sent_to_vec(ad, q + \" \" + ad)      \n",
    "            scores = [np.dot(x, vq) for x in [va, vb, vc, vd]]\n",
    "            print(qid, *scores, sep=\"\\t\", file=fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(REPTIL_VALIDATION_FEATURES, \"w\") as fo:\n",
    "    with open(VALIDATION_CLEANED, encoding=\"utf-8\") as f:\n",
    "        for i, l in enumerate(f):\n",
    "            try:\n",
    "                [qid, q, aa, ab, ac, ad] = l.strip(\"\\n\").split(\"\\t\")\n",
    "            except ValueError:\n",
    "                print(l)\n",
    "            vq = sent_to_vec(q, q)\n",
    "            va = sent_to_vec(aa, q + \" \" + aa)\n",
    "            vb = sent_to_vec(ab, q + \" \" + ab)\n",
    "            vc = sent_to_vec(ac, q + \" \" + ac)\n",
    "            vd = sent_to_vec(ad, q + \" \" + ad)      \n",
    "            scores = [np.dot(x, vq) for x in [va, vb, vc, vd]]\n",
    "            print(qid, *scores, sep=\"\\t\", file=fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reptil parameters\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`sh train.sh --min-freq 10 --window 4 --workers 48 --epochs 5 --dim 300 --alpha 0.1 /root/data/allen-ai-challenge/merged_corpus.txt /root/data/allen-ai-challenge/adam.dict /root/data/allen-ai-challenge/adam.model\n",
    "0.3972\n",
    "\n",
    "sh train.sh --min-freq 5 --window 4 --workers 48 --epochs 5 --dim 300 --alpha 0.1 /root/data/allen-ai-challenge/merged_corpus.txt /root/data/allen-ai-challenge/adam.dict /root/data/allen-ai-challenge/adam.model\n",
    "0.39119\n",
    "\n",
    "sh train.sh --min-freq 20 --window 5 --workers 48 --epochs 5 --dim 300 --alpha 0.1 /root/data/allen-ai-challenge/merged_corpus.txt /root/data/allen-ai-challenge/adam.dict /root/data/allen-ai-challenge/adam.model\n",
    "0.413\n",
    "\n",
    "sh train.sh --min-freq 30 --window 5 --workers 48 --epochs 5 --dim 300 --alpha 0.1 /root/data/allen-ai-challenge/merged_corpus.txt /root/data/allen-ai-challenge/adam.dict /root/data/allen-ai-challenge/adam.model\n",
    "0.3992\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
