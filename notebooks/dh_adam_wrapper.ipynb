{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import os, sys\n",
    "from os.path import join\n",
    "import json\n",
    "from codecs import open\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/cuda-7.5/lib64:/root/reps/AdaGram.jl/lib'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"LD_LIBRARY_PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdaGramModel(object):\n",
    "    \n",
    "    def __init__(self, path_to_model, path_to_dict):\n",
    "        self.j = julia.Julia()\n",
    "        self.j.eval(\"using AdaGram\")\n",
    "        self.j.eval('vm, dict = load_model(\"%s\")' % path_to_model)\n",
    "        self.d = j.eval('size(vm.In, 1)') # size of word vectors\n",
    "        self.m = j.eval('size(vm.In, 2)') # number of context \n",
    "        self.n = j.eval('size(vm.In, 3)') # number of vectors\n",
    "        # TODO: how to get Py dict from Julia dict?\n",
    "        self.dictionary = dict()\n",
    "        with open(path_to_dict) as f:\n",
    "            next(f) # skip strange empty token\n",
    "            for l in f:\n",
    "                r = l.strip().split()\n",
    "                self.dictionary[r[0]] = int(r[1])\n",
    "    \n",
    "    def expected_pi(self, word):\n",
    "        return self.j.eval('expected_pi(vm, dict.word2id[\"%s\"])' % word)\n",
    "    \n",
    "    def disambiguate(self, word, context):\n",
    "        return self.j.eval('disambiguate(vm, dict, \"%s\", split(\"%s\"))' % (word, context))\n",
    "    \n",
    "    def vec(self, word, pi):\n",
    "        assert pi + 1 <= self.m, \"n of prototypes mismatch\"\n",
    "        return j.eval('vec(vm, dict, \"%s\", %d)' % (word, pi + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ROOT_DATA = join(os.environ[\"HOME\"], \"data/allen-ai-challenge\")\n",
    "TRAINING_CLEANED = join(ROOT_DATA, \"training_set_cleaned.tsv\")\n",
    "VALIDATION_CLEANED = join(ROOT_DATA, \"validation_set_cleaned.tsv\")\n",
    "MERGED = join(ROOT_DATA, \"merged_corpus.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ADAGRAM_MODEL = join(ROOT_DATA, \"adam_long_%d.model\" % N)\n",
    "ADAGRAM_DICT = join(ROOT_DATA, \"adam.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "am = AdaGramModel(ADAGRAM_MODEL, ADAGRAM_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%sh\n",
    "# /root/reps/AdaGram.jl/utils/dictionary.sh /root/data/allen-ai-challenge/merged_corpus.txt /root/data/allen-ai-challenge/adam.dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# %%sh\n",
    "# /root/reps/AdaGram.jl/train.sh --min-freq 5 --window 5 --workers 47 --epochs 10 --dim 300 --alpha 0.15 /root/data/allen-ai-challenge/merged_corpus.txt /root/data/allen-ai-challenge/adam.dict /root/data/allen-ai-challenge/adam.model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_dict(t):\n",
    "    return [w for w in t.split() if w in am.dictionary and am.dictionary[w] >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sent_to_vec(sent, context):\n",
    "    v = np.zeros((N,), dtype='float32')\n",
    "    fc = filter_dict(context)\n",
    "    fs = filter_dict(sent)\n",
    "    c = 1\n",
    "    if fs:\n",
    "        c = 0\n",
    "        for w in fs:\n",
    "            fc_cut = fc\n",
    "#             fc_cut.remove(w)\n",
    "            pi = am.disambiguate(w, \" \".join(fc_cut)).argmax()\n",
    "            vv = am.vec(w, pi)\n",
    "            v += vv\n",
    "            c += 1\n",
    "    return v / c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 81.7 ms, total: 1min 3s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tries = []\n",
    "with open(TRAINING_CLEANED, encoding=\"utf-8\") as f:\n",
    "    for i, l in enumerate(f):\n",
    "        [qid, q, r, aa, ab, ac, ad] = l.strip().split(\"\\t\")\n",
    "        vq = sent_to_vec(q, q)\n",
    "        va = sent_to_vec(aa, q + \" \" + aa)\n",
    "        vb = sent_to_vec(ab, q + \" \" + ab)\n",
    "        vc = sent_to_vec(ac, q + \" \" + ac)\n",
    "        vd = sent_to_vec(ad, q + \" \" + ad)\n",
    "#         va = sent_to_vec(aa, q)\n",
    "#         vb = sent_to_vec(ab, q)\n",
    "#         vc = sent_to_vec(ac, q)\n",
    "#         vd = sent_to_vec(ad, q)        \n",
    "        scores = [np.dot(x, vq) for x in [va, vb, vc, vd]]\n",
    "        g = \"ABCD\"[np.argmax(scores)]\n",
    "        tries.append(1 if g == r else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39600000000000002"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
