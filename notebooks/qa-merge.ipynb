{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import  print_function, division\n",
    "\n",
    "import nltk\n",
    "import codecs\n",
    "\n",
    "TRAINING_SET = '/home/marat/Downloads/training_set.tsv'\n",
    "TRAINING_SET_MERGED = '/home/marat/Downloads/training_set_merged.tsv'\n",
    "\n",
    "VALIDATION_SET = '/home/marat/Downloads/validation_set.tsv'\n",
    "VALIDATION_SET_MERGED = '/home/marat/Downloads/validation_set_merged.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_statement_finished(*statements):\n",
    "    return all([a[-1] in '.?' for a in statements])\n",
    "\n",
    "def extract_np(result):\n",
    "    for s in result.subtrees(filter=lambda x: x.label()=='NP'):\n",
    "        return [L[0] for L in s.leaves()]\n",
    "    \n",
    "def normalize_sentences(sents):\n",
    "    ws = []\n",
    "    for s in sents:\n",
    "        ws.extend(nltk.word_tokenize(s.lower()))\n",
    "    return ' '.join(ws)\n",
    "\n",
    "\n",
    "def fix_question(txt_q):\n",
    "    if txt_q.find('.Which'):\n",
    "        txt_q = txt_q.replace('.Which', '. Which')\n",
    "    return txt_q\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e.Which'"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = re.search(, \"Four students compared the total mass of the products to the total mass of the reactants after performing three trials of the same chemical reaction. Each student concluded that the total mass of the products was slightly less than the total mass of the reactants. Each student proposed a different explanation as follows.     Student 1: The reaction converted some of the reactant mass to energy.     Student 2: The chemical reaction produced a gas that escaped.     Student 3: Some of the mass measurements were made with insufficient precision.     Student 4: Heat released during the reaction caused the volume of the products to increase.Which students offered the most reasonable explanations?\")\n",
    "s.group()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper chromatography is a process used to separate mixtures of substances into their components. The components are carried by a mobile phase through a stationary phase made of absorbent paper. An investigation analyzed a sample of black ink to determine its components.Which property allows the components to separate?\n",
      "[u'the solubility of the components in the mobile phase', u'the evaporation rate of the components at a certain temperature', u'the magnetic property of the components', u'the thickness of the paper used as the stationary phase']\n",
      "paper chromatography is a process used to separate mixtures of substances into their components . the components are carried by a mobile phase through a stationary phase made of absorbent paper . an investigation analyzed a sample of black ink to determine its components . the solubility of the components in the mobile phase allows the components to separate .\n"
     ]
    }
   ],
   "source": [
    "which_grammar = r\"\"\"\n",
    "NP:\n",
    "{<WDT><.*>*}          # Chunk everything\n",
    "}<V.?[^G]?|MD|\\.>+{      # Chink sequences of V.*\"\"\"\n",
    "\n",
    "what_grammar = r\"\"\"\n",
    "NP:\n",
    "{<WP|WDT><.*>*}          # Chunk everything\n",
    "}<V.?[^G]?|MD|\\.>+{      # Chink sequences of V.*\"\"\"\n",
    "\n",
    "def merge_qa(question, answers):\n",
    "        sents = nltk.sent_tokenize(fix_question(question))\n",
    "        \n",
    "        new_q = ''\n",
    "        if not is_statement_finished(sents[-1]) and is_statement_finished(*answers):\n",
    "            return [normalize_sentences(sents[:-1] + [sents[-1]+ ' ' + a]) for a in answers]\n",
    "            \n",
    "        if '________' in question:\n",
    "#             assert not is_statement_finished(*answers)\n",
    "            rc = []\n",
    "            for a in answers:\n",
    "                ws = []\n",
    "                for s in sents:\n",
    "                    for w in nltk.word_tokenize(s.lower()):\n",
    "                        if '________' in w:\n",
    "                            ws.extend(nltk.word_tokenize(a.lower()))\n",
    "                        else:\n",
    "                            ws.append(w)\n",
    "                rc.append(' '.join(ws))\n",
    "            return rc\n",
    "        \n",
    "        if 'which' in sents[-1].lower() and not is_statement_finished(*answers):\n",
    "            words = nltk.word_tokenize(sents[-1].lower())\n",
    "            tagged_words = nltk.pos_tag(words)\n",
    "#             print(tagged_words)\n",
    "            \n",
    "            cp = nltk.RegexpParser(which_grammar)\n",
    "            result = cp.parse(tagged_words)\n",
    "#             print(result)\n",
    "            \n",
    "            np = ' '.join(extract_np(result))\n",
    "            rc = []\n",
    "            for a in answers:\n",
    "                new_last_qs = sents[-1].lower().replace(np, a).replace('?', '.')\n",
    "                rc.append(normalize_sentences(sents[:-1] + [new_last_qs]))\n",
    "            return rc\n",
    "        \n",
    "        if 'which' in sents[-1].lower() and is_statement_finished(*answers):\n",
    "            words = nltk.word_tokenize(sents[-1].lower())\n",
    "            new_last_qs = sents[-1].lower().replace('which', 'that').replace('?', '.')\n",
    "            return [normalize_sentences(sents[:-1] + [a.lower(), new_last_qs]) for a in answers]\n",
    "        \n",
    "        if 'what' in sents[-1].lower() and not is_statement_finished(*answers):\n",
    "            \n",
    "            words = nltk.word_tokenize(sents[-1].lower())\n",
    "            tagged_words = nltk.pos_tag(words)\n",
    "#             print(tagged_words)\n",
    "            \n",
    "            cp = nltk.RegexpParser(what_grammar)\n",
    "            result = cp.parse(tagged_words)\n",
    "#             print(result)\n",
    "            \n",
    "            np = ' '.join(extract_np(result))\n",
    "            rc = []\n",
    "            for a in answers:\n",
    "                new_last_qs = sents[-1].lower().replace(np, a).replace('?', '.')\n",
    "                rc.append(normalize_sentences(sents[:-1] + [new_last_qs]))\n",
    "            return rc\n",
    "        if 'what' in sents[-1].lower() and is_statement_finished(*answers):\n",
    "            words = nltk.word_tokenize(sents[-1].lower())\n",
    "            new_last_qs = sents[-1].lower().replace('what', 'that').replace('?', '.')\n",
    "            return [normalize_sentences(sents[:-1] + [a.lower(), new_last_qs]) for a in answers]\n",
    "        \n",
    "        return [normalize_sentences(sents + [a]) for a in answers]\n",
    "    \n",
    "qids = ['100645']\n",
    "with codecs.open(TRAINING_SET, encoding='utf8') as f:\n",
    "    f.readline()  # skip header\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        qid, q, c, aa, ab, ac, ad = line.strip().split('\\t')\n",
    "        if qid not in qids:\n",
    "            continue\n",
    "        print(q)\n",
    "        print([aa, ab, ac, ad])\n",
    "        print(merge_qa(q, [aa, ab, ac, ad])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tests = {}\n",
    "# when question is finishing directly with answers\n",
    "tests['100064'] = 'trees most likely change the environment in which they are located by releasing nitrogen in the soil .'\n",
    "# substitue _______ with answers\n",
    "tests['100192'] = 'an inherited trait is determined by a single gene .'\n",
    "tests['100306'] = 'the golgi apparatus is the structure responsible for modifying proteins , packaging proteins into vesicles , and transporting them to the plasma membrane for secretion .'\n",
    "# simple which statements\n",
    "tests['100002'] = 'smelling the air for odors describes a learned behavior in a dog .'\n",
    "tests['100004'] = 'the symptoms of the disease is a distinction between an epidemic and a pandemic .'\n",
    "tests['100007'] = 'water should a student apply to the skin if he or she gets splashed with an acid .'\n",
    "tests['100009'] = 'tension has the greatest effect on aiding the movement of blood through the human body .'\n",
    "tests['100016'] = 'helium is likely to be found in an organic compound .'\n",
    "tests['100022'] = 'mitochondrion allows nutrients to pass into cells .'\n",
    "tests['100030'] = 'some ancient greeks tried to discover the laws of the universe through thought and logic . analysis were these scientists missing .'\n",
    "tests['100066'] = 'blood pressure is often used as an indicator of cardiovascular health . blood pressure is most often measured in cmhg .'\n",
    "tests['100068'] = 'frost wedging occurs when rocks are broken into smaller pieces by water freezing and expanding in the cracks of the rock . frost wedging is considered a part of weathering .'\n",
    "# \"which\" in question, but answers are complete\n",
    "tests['100017'] = 'solid materials absorb seismic waves . that statement describes a principle scientists have used to learn more about the structure of earth \\'s interior .'\n",
    "tests['100051'] = 'a family owns a vacation cabin located on a hillside below a gas station with a leaking gasoline storage tank . water is pumped to the cabin from a distant reservoir . in that situation is the drinking water for the cabin most likely to be contaminated .'\n",
    "# \"what\" in question, answer is not complete\n",
    "tests['100001'] = 'when athletes begin to exercise , their heart rates and respiration rates increase . at at the tissue level does the human body coordinate these functions .'\n",
    "tests['100167'] = ''\n",
    "# \"what\" in question, answer is complete\n",
    "tests['100019'] = 'robots can perform tasks that are dangerous for humans . the assembly pieces must be very small . that is the major limitation to the use of robots .'\n",
    "tests['100071'] = 'a plant that grows red flowers was crossed with the same kind of plant that grows white flowers . their offspring grew pink flowers . the offspring experienced a genetic mutation . that best explains why the offspring grew pink flowers .'\n",
    "# \"why\" and others are handled in same way. Answers are appended to the question.\n",
    "tests['100096'] = 'why is competition among males during mating season important in some animal species ? it ensures that genes from the fittest animals are passed on .'\n",
    "# tests['100051'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  at/IN\n",
      "  (NP what/WP level/NN of/IN organization/NN)\n",
      "  does/VBZ\n",
      "  (NP the/DT human/JJ body/NN)\n",
      "  coordinate/VB\n",
      "  (NP these/DT functions/NNS)\n",
      "  ?/.)\n",
      "100001 is ok\n",
      "100002 is ok\n",
      "100004 is ok\n",
      "100007 is ok\n",
      "100009 is ok\n",
      "100016 is ok\n",
      "100017 is ok\n",
      "100019 is ok\n",
      "100022 is ok\n",
      "100030 is ok\n",
      "100051 is ok\n",
      "100064 is ok\n",
      "100066 is ok\n",
      "100068 is ok\n",
      "100071 is ok\n",
      "100096 is ok\n",
      "100192 is ok\n",
      "100306 is ok\n"
     ]
    }
   ],
   "source": [
    "# run tests\n",
    "qids = tests.keys()\n",
    "# qids = '100051'\n",
    "\n",
    "with codecs.open(TRAINING_SET, encoding='utf8') as f:\n",
    "    f.readline()  # skip header\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        qid, q, c, aa, ab, ac, ad = line.strip().split('\\t')\n",
    "        if qid not in qids:\n",
    "            continue        \n",
    "        merged = merge_qa(q, [aa, ab, ac, ad])\n",
    "        if tests.get(qid, '') != merged[0]:\n",
    "            print(line)\n",
    "            print(merged[0])\n",
    "            print('-'*50)\n",
    "        else:\n",
    "            print('%s is ok' % qid)\n",
    "        line = nltk.pos_tag(line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "  NP:\n",
    "    {<WDT><.*>*}          # Chunk everything\n",
    "    }<V.?[^G]?|MD|\\.>+{      # Chink sequences of VBD and IN\n",
    "  \"\"\"\n",
    "sentence = [(u'blood', 'NN'), (u'pressure', 'NN'), (u'is', 'VBZ'), (u'most', 'RBS'), (u'often', 'RB'), (u'measured', 'VBN'), (u'in', 'IN'), (u'which', 'WDT'), (u'of', 'IN'), (u'the', 'DT'), (u'following', 'VBG'), (u'units', 'NNS'), (u'?', '.')]\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "print(cp.parse(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 54s, sys: 2.96 s, total: 26min 56s\n",
      "Wall time: 26min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with codecs.open(TRAINING_SET, encoding='utf8') as f:\n",
    "    f.readline()  # skip header\n",
    "    with codecs.open(TRAINING_SET_MERGED, mode='w', encoding='utf8') as fo:\n",
    "        for line in f:\n",
    "            qid, q, c, aa, ab, ac, ad = line.strip().split('\\t')\n",
    "#             if int(qid) < 101767:\n",
    "#                 continue\n",
    "            try:\n",
    "                merged = merge_qa(q, [aa, ab, ac, ad])\n",
    "                print('\\t'.join([qid, c] + merged), file=fo)\n",
    "            except Exception as ex:\n",
    "                print(qid, ex)\n",
    "#             print(qid, q, '???', aa)\n",
    "#             print(merged[0])\n",
    "#             print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45min 45s, sys: 5.16 s, total: 45min 50s\n",
      "Wall time: 45min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with codecs.open(VALIDATION_SET, encoding='utf8') as f:\n",
    "    f.readline()  # skip header\n",
    "    with codecs.open(VALIDATION_SET_MERGED, mode='w', encoding='utf8') as fo:\n",
    "        for line in f:\n",
    "            qid, q, aa, ab, ac, ad = line.strip().split('\\t')\n",
    "            try:\n",
    "                merged = merge_qa(q, [aa, ab, ac, ad])\n",
    "                print('\\t'.join([qid, c] + merged), file=fo)\n",
    "            except Exception as ex:\n",
    "                print(qid, ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
