{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import  print_function, division\n",
    "\n",
    "import nltk\n",
    "from codecs import open\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "DATA_DIR = join(os.environ['HOME'], 'data', 'allen-ai-challenge')\n",
    "TRAINING_SET = join(DATA_DIR, 'training_set.tsv')\n",
    "TRAINING_SET_MERGED = join(DATA_DIR, 'training_set_merged.tsv')\n",
    "\n",
    "VALIDATION_SET = join(DATA_DIR, 'validation_set.tsv')\n",
    "VALIDATION_SET_MERGED = join(DATA_DIR, 'validation_set_merged.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_statement_finished(*statements):\n",
    "    return all([a[-1] in '.?' for a in statements])\n",
    "\n",
    "def extract_np(result):\n",
    "    for s in result.subtrees(filter=lambda x: x.label()=='NP'):\n",
    "        return [L[0] for L in s.leaves()]\n",
    "    \n",
    "def normalize_sentences(sents):\n",
    "    ws = []\n",
    "    for s in sents:\n",
    "        ws.extend(nltk.word_tokenize(s.lower()))\n",
    "    return ' '.join(ws)\n",
    "\n",
    "\n",
    "def fix_question(txt_q):\n",
    "    if txt_q.find('.Which'):\n",
    "        txt_q = txt_q.replace('.Which', '. Which')\n",
    "    return txt_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper chromatography is a process used to separate mixtures of substances into their components. The components are carried by a mobile phase through a stationary phase made of absorbent paper. An investigation analyzed a sample of black ink to determine its components.Which property allows the components to separate?\n",
      "[u'the solubility of the components in the mobile phase', u'the evaporation rate of the components at a certain temperature', u'the magnetic property of the components', u'the thickness of the paper used as the stationary phase']\n",
      "paper chromatography is a process used to separate mixtures of substances into their components . the components are carried by a mobile phase through a stationary phase made of absorbent paper . an investigation analyzed a sample of black ink to determine its components . the solubility of the components in the mobile phase allows the components to separate .\n"
     ]
    }
   ],
   "source": [
    "which_grammar = r\"\"\"\n",
    "NP:\n",
    "{<WDT><.*>*}          # Chunk everything\n",
    "}<V.?[^G]?|MD|\\.>+{      # Chink sequences of V.*\"\"\"\n",
    "\n",
    "what_grammar = r\"\"\"\n",
    "NP:\n",
    "{<WP|WDT><.*>*}          # Chunk everything\n",
    "}<V.?[^G]?|MD|\\.>+{      # Chink sequences of V.*\"\"\"\n",
    "\n",
    "def merge_qa(question, answers):\n",
    "        sents = nltk.sent_tokenize(fix_question(question))\n",
    "        \n",
    "        new_q = ''\n",
    "        if not is_statement_finished(sents[-1]) and is_statement_finished(*answers):\n",
    "            return [normalize_sentences(sents[:-1] + [sents[-1]+ ' ' + a]) for a in answers]\n",
    "            \n",
    "        if '________' in question:\n",
    "#             assert not is_statement_finished(*answers)\n",
    "            rc = []\n",
    "            for a in answers:\n",
    "                ws = []\n",
    "                for s in sents:\n",
    "                    for w in nltk.word_tokenize(s.lower()):\n",
    "                        if '________' in w:\n",
    "                            ws.extend(nltk.word_tokenize(a.lower()))\n",
    "                        else:\n",
    "                            ws.append(w)\n",
    "                rc.append(' '.join(ws))\n",
    "            return rc\n",
    "        \n",
    "        if 'which' in sents[-1].lower() and not is_statement_finished(*answers):\n",
    "            words = nltk.word_tokenize(sents[-1].lower())\n",
    "            tagged_words = nltk.pos_tag(words)\n",
    "#             print(tagged_words)\n",
    "            \n",
    "            cp = nltk.RegexpParser(which_grammar)\n",
    "            result = cp.parse(tagged_words)\n",
    "#             print(result)\n",
    "            \n",
    "            np = ' '.join(extract_np(result))\n",
    "            rc = []\n",
    "            for a in answers:\n",
    "                new_last_qs = sents[-1].lower().replace(np, a).replace('?', '.')\n",
    "                rc.append(normalize_sentences(sents[:-1] + [new_last_qs]))\n",
    "            return rc\n",
    "        \n",
    "        if 'which' in sents[-1].lower() and is_statement_finished(*answers):\n",
    "            words = nltk.word_tokenize(sents[-1].lower())\n",
    "            new_last_qs = sents[-1].lower().replace('which', 'that').replace('?', '.')\n",
    "            return [normalize_sentences(sents[:-1] + [a.lower(), new_last_qs]) for a in answers]\n",
    "        \n",
    "        if 'what' in sents[-1].lower() and not is_statement_finished(*answers):\n",
    "            \n",
    "            words = nltk.word_tokenize(sents[-1].lower())\n",
    "            tagged_words = nltk.pos_tag(words)\n",
    "#             print(tagged_words)\n",
    "            \n",
    "            cp = nltk.RegexpParser(what_grammar)\n",
    "            result = cp.parse(tagged_words)\n",
    "#             print(result)\n",
    "            \n",
    "            np = ' '.join(extract_np(result))\n",
    "            rc = []\n",
    "            for a in answers:\n",
    "                new_last_qs = sents[-1].lower().replace(np, a).replace('?', '.')\n",
    "                rc.append(normalize_sentences(sents[:-1] + [new_last_qs]))\n",
    "            return rc\n",
    "        if 'what' in sents[-1].lower() and is_statement_finished(*answers):\n",
    "            words = nltk.word_tokenize(sents[-1].lower())\n",
    "            new_last_qs = sents[-1].lower().replace('what', 'that').replace('?', '.')\n",
    "            return [normalize_sentences(sents[:-1] + [a.lower(), new_last_qs]) for a in answers]\n",
    "        \n",
    "        return [normalize_sentences(sents + [a]) for a in answers]\n",
    "    \n",
    "qids = ['100645']\n",
    "with open(TRAINING_SET, encoding='utf8') as f:\n",
    "    f.readline()  # skip header\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        qid, q, c, aa, ab, ac, ad = line.strip().split('\\t')\n",
    "        if qid not in qids:\n",
    "            continue\n",
    "        print(q)\n",
    "        print([aa, ab, ac, ad])\n",
    "        print(merge_qa(q, [aa, ab, ac, ad])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = {}\n",
    "# when question is finishing directly with answers\n",
    "tests['100064'] = 'trees most likely change the environment in which they are located by releasing nitrogen in the soil .'\n",
    "# substitue _______ with answers\n",
    "tests['100192'] = 'an inherited trait is determined by a single gene .'\n",
    "tests['100306'] = 'the golgi apparatus is the structure responsible for modifying proteins , packaging proteins into vesicles , and transporting them to the plasma membrane for secretion .'\n",
    "# simple which statements\n",
    "tests['100002'] = 'smelling the air for odors describes a learned behavior in a dog .'\n",
    "tests['100004'] = 'the symptoms of the disease is a distinction between an epidemic and a pandemic .'\n",
    "tests['100007'] = 'water should a student apply to the skin if he or she gets splashed with an acid .'\n",
    "tests['100009'] = 'tension has the greatest effect on aiding the movement of blood through the human body .'\n",
    "tests['100016'] = 'helium is likely to be found in an organic compound .'\n",
    "tests['100022'] = 'mitochondrion allows nutrients to pass into cells .'\n",
    "tests['100030'] = 'some ancient greeks tried to discover the laws of the universe through thought and logic . analysis were these scientists missing .'\n",
    "tests['100066'] = 'blood pressure is often used as an indicator of cardiovascular health . blood pressure is most often measured in cmhg .'\n",
    "tests['100068'] = 'frost wedging occurs when rocks are broken into smaller pieces by water freezing and expanding in the cracks of the rock . frost wedging is considered a part of weathering .'\n",
    "# \"which\" in question, but answers are complete\n",
    "tests['100017'] = 'solid materials absorb seismic waves . that statement describes a principle scientists have used to learn more about the structure of earth \\'s interior .'\n",
    "tests['100051'] = 'a family owns a vacation cabin located on a hillside below a gas station with a leaking gasoline storage tank . water is pumped to the cabin from a distant reservoir . in that situation is the drinking water for the cabin most likely to be contaminated .'\n",
    "# \"what\" in question, answer is not complete\n",
    "tests['100001'] = 'when athletes begin to exercise , their heart rates and respiration rates increase . at at the tissue level does the human body coordinate these functions .'\n",
    "tests['100167'] = ''\n",
    "# \"what\" in question, answer is complete\n",
    "tests['100019'] = 'robots can perform tasks that are dangerous for humans . the assembly pieces must be very small . that is the major limitation to the use of robots .'\n",
    "tests['100071'] = 'a plant that grows red flowers was crossed with the same kind of plant that grows white flowers . their offspring grew pink flowers . the offspring experienced a genetic mutation . that best explains why the offspring grew pink flowers .'\n",
    "# \"why\" and others are handled in same way. Answers are appended to the question.\n",
    "tests['100096'] = 'why is competition among males during mating season important in some animal species ? it ensures that genes from the fittest animals are passed on .'\n",
    "# tests['100051'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100001 is ok\n",
      "100002 is ok\n",
      "100004 is ok\n",
      "100007 is ok\n",
      "100009 is ok\n",
      "100016 is ok\n",
      "100017 is ok\n",
      "100019 is ok\n",
      "100022 is ok\n",
      "100030 is ok\n",
      "100051 is ok\n",
      "100064 is ok\n",
      "100066 is ok\n",
      "100068 is ok\n",
      "100071 is ok\n",
      "100096 is ok\n",
      "100167\tAn air mass in a valley travels up a mountainside. What causes the movement of this air?\tC\ttidal pull of the moon's gravity\tevaporation of water from soil in the valley\twarming by solar energy re-radiated from the ground\tcooling effect of ice crystals in the air over the mountain\n",
      "\n",
      "an air mass in a valley travels up a mountainside . tidal pull of the moon 's gravity causes the movement of this air .\n",
      "--------------------------------------------------\n",
      "100192 is ok\n",
      "100306 is ok\n"
     ]
    }
   ],
   "source": [
    "# run tests\n",
    "qids = tests.keys()\n",
    "# qids = '100051'\n",
    "\n",
    "with open(TRAINING_SET, encoding='utf8') as f:\n",
    "    f.readline()  # skip header\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        qid, q, c, aa, ab, ac, ad = line.strip().split('\\t')\n",
    "        if qid not in qids:\n",
    "            continue        \n",
    "        merged = merge_qa(q, [aa, ab, ac, ad])\n",
    "        if tests.get(qid, '') != merged[0]:\n",
    "            print(line)\n",
    "            print(merged[0])\n",
    "            print('-'*50)\n",
    "        else:\n",
    "            print('%s is ok' % qid)\n",
    "        line = nltk.pos_tag(line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  blood/NN\n",
      "  pressure/NN\n",
      "  is/VBZ\n",
      "  most/RBS\n",
      "  often/RB\n",
      "  measured/VBN\n",
      "  in/IN\n",
      "  (NP which/WDT of/IN the/DT following/VBG units/NNS)\n",
      "  ?/.)\n"
     ]
    }
   ],
   "source": [
    "grammar = r\"\"\"\n",
    "  NP:\n",
    "    {<WDT><.*>*}          # Chunk everything\n",
    "    }<V.?[^G]?|MD|\\.>+{      # Chink sequences of VBD and IN\n",
    "  \"\"\"\n",
    "sentence = [(u'blood', 'NN'), (u'pressure', 'NN'), (u'is', 'VBZ'), (u'most', 'RBS'), (u'often', 'RB'), (u'measured', 'VBN'), (u'in', 'IN'), (u'which', 'WDT'), (u'of', 'IN'), (u'the', 'DT'), (u'following', 'VBG'), (u'units', 'NNS'), (u'?', '.')]\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "print(cp.parse(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 56s, sys: 15.5 s, total: 24min 12s\n",
      "Wall time: 24min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(TRAINING_SET, encoding='utf8') as f:\n",
    "    f.readline()  # skip header\n",
    "    with open(TRAINING_SET_MERGED, mode='w', encoding='utf8') as fo:\n",
    "        for line in f:\n",
    "            qid, q, c, aa, ab, ac, ad = line.strip().split('\\t')\n",
    "#             if int(qid) < 101767:\n",
    "#                 continue\n",
    "            try:\n",
    "                merged = merge_qa(q, [aa, ab, ac, ad])\n",
    "                print('\\t'.join([qid, c, q] + merged), file=fo)\n",
    "            except Exception as ex:\n",
    "                print(qid, ex)\n",
    "#             print(qid, q, '???', aa)\n",
    "#             print(merged[0])\n",
    "#             print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42min 40s, sys: 23.7 s, total: 43min 4s\n",
      "Wall time: 43min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(VALIDATION_SET, encoding='utf8') as f:\n",
    "    f.readline()  # skip header\n",
    "    with open(VALIDATION_SET_MERGED, mode='w', encoding='utf8') as fo:\n",
    "        for line in f:\n",
    "            qid, q, aa, ab, ac, ad = line.strip().split('\\t')\n",
    "            try:\n",
    "                merged = merge_qa(q, [aa, ab, ac, ad])\n",
    "                print('\\t'.join([qid, c, q] + merged), file=fo)\n",
    "            except Exception as ex:\n",
    "                print(qid, ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}