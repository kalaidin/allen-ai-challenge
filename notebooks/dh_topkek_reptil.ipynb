{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, unicode_literals\n",
    "import six\n",
    "import os\n",
    "from os.path import join\n",
    "import json\n",
    "from codecs import open\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/cuda-7.5/lib64:/root/reps/AdaGram.jl/lib'"
      ]
     },
     "execution_count": 2,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "os.environ[\"LD_LIBRARY_PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = join(os.environ['HOME'], 'data/allen-ai-challenge')\n",
    "CORPUS = join(DATA_DIR, 'corpus_paragraph_roman_2_short150-100.txt')\n",
    "\n",
    "TRAINING_SET = join(DATA_DIR, 'training_set_cleaned.tsv')\n",
    "VALIDATION_SET = join(DATA_DIR, 'validation_set_cleaned.tsv')\n",
    "\n",
    "INDEX_DIR = join(DATA_DIR, 'index_merged_corpus_long_topkek_x_15')\n",
    "SUBMISSION = join(DATA_DIR, 'submissions/lucene_more_data_plus_topkek_cleaned.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w2v\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import julia\n",
    "\n",
    "class AdaGramModel(object):\n",
    "    \n",
    "    def __init__(self, path_to_model, path_to_dict):\n",
    "        self.j = julia.Julia()\n",
    "        self.j.eval(\"using AdaGram\")\n",
    "        self.j.eval('vm, dict = load_model(\"%s\")' % path_to_model)\n",
    "        self.d = self.j.eval('size(vm.In, 1)') # size of word vectors\n",
    "        self.m = self.j.eval('size(vm.In, 2)') # number of context \n",
    "        self.n = self.j.eval('size(vm.In, 3)') # number of vectors\n",
    "        # TODO: AdaGram.Dictionary -> Python dict()?\n",
    "        self.dictionary = dict()\n",
    "        with open(path_to_dict) as f:\n",
    "            next(f) # skip strange empty token\n",
    "            for l in f:\n",
    "                r = l.strip().split()\n",
    "                self.dictionary[r[0]] = int(r[1])\n",
    "    \n",
    "    def expected_pi(self, word):\n",
    "        return self.j.eval('expected_pi(vm, dict.word2id[\"%s\"])' % word)\n",
    "    \n",
    "    def disambiguate(self, word, context):\n",
    "        return self.j.eval('disambiguate(vm, dict, \"%s\", split(\"%s\"))' % (word, context))\n",
    "    \n",
    "    def vec(self, word, pi):\n",
    "        assert pi + 1 <= self.m, \"n of prototypes mismatch\"\n",
    "        return self.j.eval('vec(vm, dict, \"%s\", %d)' % (word, pi + 1))\n",
    "    \n",
    "    def nearest_neighbors(self, word, pi):\n",
    "        return self.j.eval('nearest_neighbors(vm, dict, \"%s\", %d)' % (word, pi + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADAGRAM_MODEL = join(DATA_DIR, \"adam.model\")\n",
    "ADAGRAM_DICT = join(DATA_DIR, \"adam.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "am = AdaGramModel(ADAGRAM_MODEL, ADAGRAM_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dict(t):\n",
    "    return [w for w in t.split() if w in am.dictionary and am.dictionary[w] >= 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_vec(sent, context):\n",
    "    v = np.zeros((N,), dtype='float32')\n",
    "    fc = filter_dict(context)\n",
    "    fs = filter_dict(sent)\n",
    "    if not fs:\n",
    "        return v\n",
    "    c = 0\n",
    "    for w in fs:\n",
    "        fc_cut = fc\n",
    "        # fc_cut.remove(w) # not helping\n",
    "        pi = am.disambiguate(w, \" \".join(fc_cut)).argmax()\n",
    "        vv = am.vec(w, pi)\n",
    "        v += vv\n",
    "        c += 1\n",
    "    return v / c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lucene\n",
    "lucene.initVM()\n",
    "\n",
    "from org.apache.lucene.analysis.standard import StandardAnalyzer\n",
    "from org.apache.lucene.analysis.shingle import ShingleAnalyzerWrapper\n",
    "from org.apache.lucene.document import Document, Field\n",
    "from org.apache.lucene.index import IndexWriter, IndexWriterConfig, IndexReader\n",
    "from org.apache.lucene.search import IndexSearcher\n",
    "from org.apache.lucene.search import Sort, SortField\n",
    "from org.apache.lucene.queryparser.classic import QueryParser\n",
    "from org.apache.lucene.store import SimpleFSDirectory\n",
    "from org.apache.lucene.util import Version\n",
    "\n",
    "from java.io import File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lucene Index Creation\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = StandardAnalyzer(Version.LUCENE_4_10_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shingle_analyzer = ShingleAnalyzerWrapper(analyzer, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "writerConfig = IndexWriterConfig(Version.LUCENE_4_10_1, analyzer)\n",
    "writer = IndexWriter(SimpleFSDirectory(File(INDEX_DIR)), writerConfig)\n",
    "\n",
    "def add_document(doc_text):\n",
    "    doc = Document()\n",
    "    doc.add(Field(\"text\", doc_text, Field.Store.YES, Field.Index.ANALYZED))\n",
    "    writer.addDocument(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 8s, sys: 2.05 s, total: 2min 10s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(CORPUS, encoding='utf8') as f:\n",
    "    for line in (line.strip() for line in f):\n",
    "        add_document(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3693751\n"
     ]
    }
   ],
   "source": [
    "print(writer.numDocs())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_data(datafile, has_correct_answer=True, skip_first_line=False):\n",
    "    with open(datafile, encoding='utf-8', errors='ignore') as f:\n",
    "        if not skip_first_line:\n",
    "            next(f)\n",
    "        for l in f:\n",
    "            if has_correct_answer:\n",
    "                idd, q, correct, aa, ab, ac, ad = l.strip().split(\"\\t\")\n",
    "            else:\n",
    "                idd, q, aa, ab, ac, ad = l.strip('\\n').split(\"\\t\")\n",
    "                correct = \"no\"\n",
    "            yield {\"idd\": idd, \"q\": q, \"correct\": correct, \"aa\": aa, \"ab\": ab, \"ac\": ac, \"ad\": ad}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 30s, sys: 5.53 s, total: 3min 36s\n",
      "Wall time: 3min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = defaultdict(list)\n",
    "MAX = 100\n",
    "docs_per_q = range(1, MAX)\n",
    "\n",
    "analyzer = StandardAnalyzer(Version.LUCENE_4_10_1)\n",
    "reader = IndexReader.open(SimpleFSDirectory(File(INDEX_DIR)))\n",
    "searcher = IndexSearcher(reader)\n",
    "\n",
    "for row in iter_data(TRAINING_SET):\n",
    "#     vq = sent_to_vec(row['q'], row['q'])\n",
    "#     va = sent_to_vec(row['aa'], row['q'] + \" \" + row['aa'])\n",
    "#     vb = sent_to_vec(row['ab'], row['q'] + \" \" + row['ab'])\n",
    "#     vc = sent_to_vec(row['ac'], row['q'] + \" \" + row['ac'])\n",
    "#     vd = sent_to_vec(row['ad'], row['q'] + \" \" + row['ad'])\n",
    "#     adam_scores = [np.dot(x, vq) for x in [va, vb, vc, vd]]\n",
    "    queries = [row['aa'], row['ab'], row['ac'], row['ad']]\n",
    "    queries = [row['q'] + ' ' + q  for q in queries]\n",
    "    scores = defaultdict(list)\n",
    "    for q in queries:\n",
    "        query = QueryParser(Version.LUCENE_4_10_1, \"text\", analyzer).parse(q)\n",
    "        hits = searcher.search(query, MAX)\n",
    "        doc_importance = [hit.score for hit in hits.scoreDocs]\n",
    "        for n in docs_per_q:\n",
    "            scores[n].append(sum(doc_importance[:n]))\n",
    "    for n in docs_per_q:\n",
    "#         res[n].append(['A','B','C','D'][np.argmax(adam_scores)] == row[\"correct\"])\n",
    "        res[n].append(['A','B','C','D'][np.argmax(scores[n])] == row[\"correct\"])\n",
    "#         res[n].append(['A','B','C','D'][np.argmax(np.mean([adam_scores, scores[n]], axis=0))] == row[\"correct\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new reptil cleaned topkek 0.3\n",
    "`1 0.521008403361\n",
    "2 0.525410164066\n",
    "3 0.52781112445\n",
    "4 0.534213685474\n",
    "5 0.535414165666\n",
    "6 0.530612244898\n",
    "7 0.53181272509\n",
    "8 0.53381352541\n",
    "9 0.532212885154\n",
    "10 0.52981192477\n",
    "11 0.529411764706\n",
    "12 0.527010804322\n",
    "13 0.52581032413\n",
    "14 0.526210484194`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#topkek cleaned filt\n",
    "`1 0.512204881953\n",
    "2 0.519807923169\n",
    "3 0.52380952381\n",
    "4 0.532613045218\n",
    "5 0.531012404962\n",
    "6 0.52781112445\n",
    "7 0.528611444578\n",
    "8 0.532212885154\n",
    "9 0.530212084834\n",
    "10 0.528611444578\n",
    "11 0.526610644258\n",
    "12 0.524609843938\n",
    "13 0.523409363745`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#topkek adagram 150-100 reptil roman 2 more\n",
    "`1 0.510604241697\n",
    "2 0.519407763105\n",
    "3 0.52380952381\n",
    "4 0.532212885154\n",
    "5 0.53181272509\n",
    "6 0.528211284514\n",
    "7 0.529411764706\n",
    "8 0.533013205282\n",
    "9 0.531412565026\n",
    "10 0.528211284514\n",
    "11 0.527410964386\n",
    "12 0.524209683874\n",
    "13 0.524209683874`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.510604241697\n",
      "2 0.519407763105\n",
      "3 0.52380952381\n",
      "4 0.532212885154\n",
      "5 0.53181272509\n",
      "6 0.528211284514\n",
      "7 0.529411764706\n",
      "8 0.533013205282\n",
      "9 0.531412565026\n",
      "10 0.528211284514\n",
      "11 0.527410964386\n",
      "12 0.524209683874\n",
      "13 0.524209683874\n",
      "14 0.525410164066\n",
      "15 0.525010004002\n",
      "16 0.524209683874\n",
      "17 0.521808723489\n",
      "18 0.521808723489\n",
      "19 0.521808723489\n",
      "20 0.520208083233\n",
      "21 0.521808723489\n",
      "22 0.521808723489\n",
      "23 0.520608243297\n",
      "24 0.522208883553\n",
      "25 0.521008403361\n",
      "26 0.522208883553\n",
      "27 0.522208883553\n",
      "28 0.521808723489\n",
      "29 0.520608243297\n",
      "30 0.520208083233\n",
      "31 0.521808723489\n",
      "32 0.521808723489\n",
      "33 0.521008403361\n",
      "34 0.521408563425\n",
      "35 0.521008403361\n",
      "36 0.522609043617\n",
      "37 0.522208883553\n",
      "38 0.522609043617\n",
      "39 0.523009203681\n",
      "40 0.523009203681\n",
      "41 0.521808723489\n",
      "42 0.522208883553\n",
      "43 0.522609043617\n",
      "44 0.52380952381\n",
      "45 0.524209683874\n",
      "46 0.52380952381\n",
      "47 0.524209683874\n",
      "48 0.523409363745\n",
      "49 0.523009203681\n",
      "50 0.522609043617\n",
      "51 0.522208883553\n",
      "52 0.52380952381\n",
      "53 0.523409363745\n",
      "54 0.522208883553\n",
      "55 0.521808723489\n",
      "56 0.522208883553\n",
      "57 0.521808723489\n",
      "58 0.521008403361\n",
      "59 0.520608243297\n",
      "60 0.521008403361\n",
      "61 0.521008403361\n",
      "62 0.521008403361\n",
      "63 0.520608243297\n",
      "64 0.519807923169\n",
      "65 0.519007603041\n",
      "66 0.519007603041\n",
      "67 0.519007603041\n",
      "68 0.520608243297\n",
      "69 0.521008403361\n",
      "70 0.521408563425\n",
      "71 0.521008403361\n",
      "72 0.520608243297\n",
      "73 0.520608243297\n",
      "74 0.521408563425\n",
      "75 0.521008403361\n",
      "76 0.521008403361\n",
      "77 0.520608243297\n",
      "78 0.521808723489\n",
      "79 0.521408563425\n",
      "80 0.521808723489\n",
      "81 0.521808723489\n",
      "82 0.520608243297\n",
      "83 0.520208083233\n",
      "84 0.519407763105\n",
      "85 0.519407763105\n",
      "86 0.519007603041\n",
      "87 0.519807923169\n",
      "88 0.519007603041\n",
      "89 0.518607442977\n",
      "90 0.519007603041\n",
      "91 0.519007603041\n",
      "92 0.518207282913\n",
      "93 0.518207282913\n",
      "94 0.517807122849\n",
      "95 0.516606642657\n",
      "96 0.516206482593\n",
      "97 0.515806322529\n",
      "98 0.515406162465\n",
      "99 0.515806322529\n"
     ]
    }
   ],
   "source": [
    "for x in sorted(res):\n",
    "    print(x, np.mean(res[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topkek reptil cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1 0.518607442977\n",
    "2 0.521008403361\n",
    "3 0.523409363745\n",
    "4 0.534213685474\n",
    "5 0.533413365346\n",
    "6 0.527410964386\n",
    "7 0.529411764706\n",
    "8 0.530612244898\n",
    "9 0.528211284514\n",
    "10 0.525410164066\n",
    "11 0.526610644258\n",
    "12 0.524609843938\n",
    "13 0.521008403361\n",
    "14 0.523409363745\n",
    "15 0.521408563425\n",
    "16 0.522208883553\n",
    "17 0.521808723489\n",
    "18 0.519807923169\n",
    "19 0.521808723489`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topkek cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "1 0.509403761505\n",
    "2 0.517807122849\n",
    "3 0.522208883553\n",
    "4 0.532613045218\n",
    "5 0.531412565026\n",
    "6 0.525010004002\n",
    "7 0.52781112445\n",
    "8 0.52981192477\n",
    "9 0.527410964386\n",
    "10 0.525010004002\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topkek - adm 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    " 0.517006802721\n",
    "2 0.520208083233\n",
    "3 0.523009203681\n",
    "4 0.523409363745\n",
    "5 0.52781112445\n",
    "6 0.526210484194\n",
    "7 0.527010804322\n",
    "8 0.526210484194\n",
    "9 0.528211284514\n",
    "10 0.527410964386\n",
    "11 0.529011604642\n",
    "12 0.52581032413\n",
    "13 0.525010004002\n",
    "14 0.524609843938\n",
    "15 0.523009203681\n",
    "16 0.521408563425\n",
    "17 0.522208883553`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topkek luc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1 0.513805522209\n",
    "2 0.519007603041\n",
    "3 0.52380952381\n",
    "4 0.522609043617\n",
    "5 0.525010004002\n",
    "6 0.525410164066\n",
    "7 0.527010804322\n",
    "8 0.526610644258\n",
    "9 0.529411764706\n",
    "10 0.527010804322\n",
    "11 0.52781112445\n",
    "12 0.524209683874\n",
    "13 0.525410164066\n",
    "14 0.523409363745\n",
    "15 0.522609043617\n",
    "16 0.521808723489\n",
    "17 0.521408563425`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#backup luc #kek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1 0.488995598239\n",
    "2 0.509803921569\n",
    "3 0.511804721889\n",
    "4 0.512204881953\n",
    "5 0.513405362145\n",
    "6 0.508603441377\n",
    "7 0.511804721889\n",
    "8 0.510204081633\n",
    "9 0.511804721889\n",
    "10 0.511004401761\n",
    "11 0.512605042017\n",
    "12 0.513805522209\n",
    "13 0.514605842337\n",
    "14 0.513005202081\n",
    "15 0.515806322529\n",
    "16 0.515406162465\n",
    "17 0.515006002401\n",
    "18 0.516206482593\n",
    "19 0.516206482593\n",
    "20 0.516606642657\n",
    "21 0.517406962785\n",
    "22 0.519007603041\n",
    "23 0.516606642657\n",
    "24 0.513005202081\n",
    "25 0.512605042017\n",
    "26 0.513405362145\n",
    "27 0.513405362145\n",
    "28 0.512605042017\n",
    "29 0.511004401761\n",
    "30 0.510204081633\n",
    "31 0.508603441377\n",
    "32 0.507803121248\n",
    "33 0.50700280112\n",
    "34 0.504601840736\n",
    "35 0.504201680672\n",
    "36 0.504201680672\n",
    "37 0.5050020008\n",
    "38 0.504601840736\n",
    "39 0.503801520608\n",
    "40 0.504201680672\n",
    "41 0.503401360544\n",
    "42 0.503401360544\n",
    "43 0.503401360544\n",
    "44 0.502601040416\n",
    "45 0.501800720288\n",
    "46 0.502200880352\n",
    "47 0.503401360544\n",
    "48 0.502601040416\n",
    "49 0.502200880352`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1 0.47619047619\n",
    "2 0.495398159264\n",
    "3 0.4949979992\n",
    "4 0.500200080032\n",
    "5 0.497398959584\n",
    "6 0.498599439776\n",
    "7 0.499799919968\n",
    "8 0.495798319328\n",
    "9 0.493397358944\n",
    "10 0.49299719888\n",
    "11 0.490996398559\n",
    "12 0.491396558623\n",
    "13 0.493797519008\n",
    "14 0.491396558623\n",
    "15 0.491796718687\n",
    "16 0.49299719888\n",
    "17 0.492597038816\n",
    "18 0.491396558623\n",
    "19 0.491396558623`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 26s, sys: 12.1 s, total: 7min 38s\n",
      "Wall time: 7min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "docs_to_consider = 8\n",
    "\n",
    "analyzer = StandardAnalyzer(Version.LUCENE_4_10_1)\n",
    "reader = IndexReader.open(SimpleFSDirectory(File(INDEX_DIR)))\n",
    "searcher = IndexSearcher(reader)\n",
    "\n",
    "with open(SUBMISSION, \"w\") as s:\n",
    "    print(\"id,correctAnswer\", file=s)\n",
    "    for row in iter_data(VALIDATION_SET, False, skip_first_line=True):\n",
    "#         vq = sent_to_vec(row['q'], row['q'])\n",
    "#         va = sent_to_vec(row['aa'], row['q'] + \" \" + row['aa'])\n",
    "#         vb = sent_to_vec(row['ab'], row['q'] + \" \" + row['ab'])\n",
    "#         vc = sent_to_vec(row['ac'], row['q'] + \" \" + row['ac'])\n",
    "#         vd = sent_to_vec(row['ad'], row['q'] + \" \" + row['ad'])\n",
    "#         adam_scores = [0.3 * np.dot(x, vq) for x in [va, vb, vc, vd]]\n",
    "        queries = [row['aa'], row['ab'], row['ac'], row['ad']]\n",
    "        queries = [row['q'] + ' ' + q  for q in queries]\n",
    "        scores = []\n",
    "        for q in queries:\n",
    "            query = QueryParser(Version.LUCENE_4_10_1, \"text\", analyzer).parse(q)\n",
    "            hits = searcher.search(query, docs_to_consider)\n",
    "            doc_importance = [hit.score for hit in hits.scoreDocs]\n",
    "            scores.append(sum(doc_importance))\n",
    "#         guess = \"ABCD\"[np.argmax(np.mean([adam_scores, scores], axis=0))]\n",
    "        guess = \"ABCD\"[np.argmax(scores)]\n",
    "        s.write(\"%s,%s\\n\" % (row[\"idd\"], guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_LUCENE_ALL_SCORES = join(DATA_DIR, 'features/lucene_all.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "MAX = 10\n",
    "analyzer = StandardAnalyzer(Version.LUCENE_4_10_1)\n",
    "reader = IndexReader.open(SimpleFSDirectory(File(INDEX_DIR)))\n",
    "searcher = IndexSearcher(reader)\n",
    "\n",
    "output_file = join(DATA_DIR, 'features', 'lucene_cumsum%d.tsv' % MAX)\n",
    "with open(output_file, \"w\") as fs:\n",
    "    for row in iter_data(TRAINING_SET):\n",
    "        queries = [row['aa'], row['ab'], row['ac'], row['ad']]\n",
    "        queries = [row['q'] + ' ' + q  for q in queries]\n",
    "        features = []\n",
    "        for q in queries:\n",
    "            query = QueryParser(Version.LUCENE_4_10_1, \"text\", analyzer).parse(re.sub(\"[^a-zA-Z0-9]\",\" \", q))\n",
    "            hits = searcher.search(query, MAX)\n",
    "            doc_importances = [hit.score for hit in hits.scoreDocs]\n",
    "            features.append(\";\".join(str(d) for d in doc_importances))\n",
    "        print(row[\"idd\"], row[\"correct\"], *features, file=fs, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "###### OUTPUT VECTORS\n",
    "out_vec_dim = 7\n",
    "training = True\n",
    "\n",
    "if training:\n",
    "    working_dataset = TRAINING_SET\n",
    "    output_filename = 'lucene_vecs%d.tsv' % out_vec_dim\n",
    "else:\n",
    "    working_dataset = VALIDATION_SET\n",
    "    output_filename = 'lucene_vecs%d_submission.tsv' % out_vec_dim\n",
    "\n",
    "analyzer = StandardAnalyzer(Version.LUCENE_4_10_1)\n",
    "reader = IndexReader.open(SimpleFSDirectory(File(INDEX_DIR)))\n",
    "searcher = IndexSearcher(reader)\n",
    "\n",
    "output_file = join(DATA_DIR, 'features', output_filename)\n",
    "\n",
    "with open(output_file, \"w\") as fs:\n",
    "    for row in iter_data(working_dataset, training):\n",
    "        queries = [row['aa'], row['ab'], row['ac'], row['ad']]\n",
    "        queries = [row['q'] + ' ' + q  for q in queries]\n",
    "        features = []\n",
    "        for q in queries:\n",
    "            query = QueryParser(Version.LUCENE_4_10_1, \"text\", analyzer).parse(re.sub(\"[^a-zA-Z0-9]\",\" \", q))\n",
    "            hits = searcher.search(query, out_vec_dim)\n",
    "            doc_importances = [hit.score for hit in hits.scoreDocs]\n",
    "            features.append(\";\".join(str(d) for d in np.cumsum(doc_importances)))\n",
    "        print(row[\"idd\"], row[\"correct\"], *features, file=fs, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "MAX = 13000\n",
    "analyzer = StandardAnalyzer(Version.LUCENE_4_10_1)\n",
    "reader = IndexReader.open(SimpleFSDirectory(File(INDEX_DIR)))\n",
    "searcher = IndexSearcher(reader)\n",
    "\n",
    "with open(FEATURES_LUCENE_ALL_SCORES, \"w\") as fs:\n",
    "    for row in iter_data(TRAINING_SET):\n",
    "        queries = [row['aa'], row['ab'], row['ac'], row['ad']]\n",
    "        queries = [row['q'] + ' ' + q  for q in queries]\n",
    "        features = []\n",
    "        for q in queries:\n",
    "            query = QueryParser(Version.LUCENE_4_10_1, \"text\", analyzer).parse(re.sub(\"[^a-zA-Z0-9]\",\" \", q))      \n",
    "            hits = searcher.search(query, MAX)\n",
    "            doc_importances = {hit.doc: hit.score for hit in hits.scoreDocs}\n",
    "#             features.append(\";\".join(doc_importances))\n",
    "#             print(doc_importances)\n",
    "            break\n",
    "#         print(row[\"idd\"], row[\"correct\"], *features, file=fs, sep=\"\\t\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(doc_importances.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}