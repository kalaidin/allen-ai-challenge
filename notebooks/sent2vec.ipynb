{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import codecs\n",
    "import random\n",
    "import nltk\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA = \"/Users/Pavel/Code/allen-ai-challenge/data/ck12_tokens.txt\"\n",
    "DATA = \"/home/marat/ck12_tokens.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GLOVE_D = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GLOVE_FILE = \"/home/marat/data/glove.6B/glove.6B.%dd.txt\" % GLOVE_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_dict(fname):\n",
    "    d = {}\n",
    "    with codecs.open(fname, encoding=\"utf-8\") as f:\n",
    "        for row in (line.strip().split() for line in f):\n",
    "            w = row[0]\n",
    "            v = np.array(row[1:], dtype='float32')\n",
    "            assert v.shape == (GLOVE_D,)\n",
    "            d[w] = v\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GLOVE = read_dict(GLOVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(GLOVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text2vec(text, glove_dict, seq_length, debug=False):\n",
    "    vecs = []\n",
    "    for w in text.split():\n",
    "        try:\n",
    "            vecs.append(glove_dict[w][np.newaxis, :])\n",
    "        except KeyError:\n",
    "            if debug:\n",
    "                print(\"%s is not found\" % w)\n",
    "            continue\n",
    "    if not vecs:\n",
    "        print(\"no vector for '%s'\" % text)\n",
    "    rec = np.concatenate(vecs, axis=0).astype('float32')\n",
    "    if rec.shape[0] > seq_length:\n",
    "        # trim long sentences\n",
    "        rec = rec[rec.shape[0] - seq_length:, :]\n",
    "    elif rec.shape[0] < seq_length:\n",
    "        # extend short sentences with zeros\n",
    "        rec = np.vstack([np.zeros((seq_length - rec.shape[0], rec.shape[1])), rec])\n",
    "    assert rec.shape[0] == seq_length\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#text2vec(\"hello , die\", GLOVE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 18s, sys: 1.65 s, total: 2min 20s\n",
      "Wall time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "i=0\n",
    "sentences = []\n",
    "with codecs.open(DATA, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        sentences.append(line.strip())\n",
    "        i += 1\n",
    "        \n",
    "blob = TextBlob(' '.join(sentences))\n",
    "all_pos_tags = blob.tags        \n",
    "\n",
    "i = 0\n",
    "pos_tags = []\n",
    "for l, line in enumerate(sentences):    \n",
    "    tags = []\n",
    "    for word in line.split():\n",
    "#         if l == 63798:\n",
    "#             print(word, i, all_pos_tags[i])\n",
    "        if word.replace(\".\", \"\") == all_pos_tags[i][0].replace(\".\", \"\"):\n",
    "            tags.append(all_pos_tags[i][1])\n",
    "            i += 1\n",
    "        else:\n",
    "            tags.append('.')\n",
    "            \n",
    "    pos_tags.append(tags)\n",
    "#     if l == 63798:\n",
    "#         print(line, tags)\n",
    "#         break\n",
    "    \n",
    "del all_pos_tags\n",
    "\n",
    "assert len(sentences) == len(pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CC Coordinating conjunction\n",
    "CD Cardinal number\n",
    "DT Determiner\n",
    "EX Existential there\n",
    "FW Foreign word\n",
    "IN Preposition or subordinating conjunction\n",
    "JJ Adjective\n",
    "JJR Adjective, comparative\n",
    "JJS Adjective, superlative\n",
    "LS List item marker\n",
    "MD Modal\n",
    "NN Noun, singular or mass\n",
    "NNS Noun, plural\n",
    "NNP Proper noun, singular\n",
    "NNPS Proper noun, plural\n",
    "PDT Predeterminer\n",
    "POS Possessive ending\n",
    "PRP Personal pronoun\n",
    "PRP$ Possessive pronoun\n",
    "RB Adverb\n",
    "RBR Adverb, comparative\n",
    "RBS Adverb, superlative\n",
    "RP Particle\n",
    "SYM Symbol\n",
    "TO to\n",
    "UH Interjection\n",
    "VB Verb, base form\n",
    "VBD Verb, past tense\n",
    "VBG Verb, gerund or present participle\n",
    "VBN Verb, past participle\n",
    "VBP Verb, non­3rd person singular present\n",
    "VBZ Verb, 3rd person singular present\n",
    "WDT Wh­determiner\n",
    "WP Wh­pronoun\n",
    "WP$ Possessive wh­pronoun\n",
    "WRB Wh­adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CORRUPT_WINDOW = 10\n",
    "def corrupt(sentences, pos_tags, index):\n",
    "    s = sentences[index].split()\n",
    "    noun_indices = [i for i, tag in enumerate(pos_tags[index]) if tag.startswith('NN')]\n",
    "    if not noun_indices:\n",
    "        return None\n",
    "    noun_to_replace_index = random.choice(noun_indices)\n",
    "    all_donor_indices = range(max(0, index-CORRUPT_WINDOW), index) + \\\n",
    "                        range(index+1, min(len(sentences), index+CORRUPT_WINDOW+1))\n",
    "    donor_index = random.choice(all_donor_indices)\n",
    "    all_nouns_to_insert = [sentences[donor_index].split()[i] for i, tag in enumerate(pos_tags[donor_index])\n",
    "                                    if tag.startswith('NN')]\n",
    "    if not all_nouns_to_insert:\n",
    "        return None\n",
    "    noun_to_insert = random.choice(all_nouns_to_insert)\n",
    "    s[noun_to_replace_index] = noun_to_insert\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'hydrogen gas is bubbled through the liquid oil and reacts with the carbon-carbon double bonds present in the long-chain fatty acids .',\n",
       " None)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 75000\n",
    "sentences[c], corrupt(sentences, pos_tags, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'CD',\n",
       " '.',\n",
       " '.',\n",
       " u'VB',\n",
       " u'JJ',\n",
       " u'NN',\n",
       " '.',\n",
       " u'NN',\n",
       " '.',\n",
       " '.',\n",
       " u'VB',\n",
       " u'JJ',\n",
       " u'NN',\n",
       " '.',\n",
       " '.']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tags[63798]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('large.a.01.big')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset(\"small.a.01\").lemmas()[1].antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling functions ...\n",
      "CPU times: user 2.35 s, sys: 152 ms, total: 2.5 s\n",
      "Wall time: 6.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "\n",
    "SEQ_LENGTH = 30\n",
    "MARGIN = 1\n",
    "\n",
    "l_in = lasagne.layers.InputLayer(shape=(None, GLOVE_D, SEQ_LENGTH))\n",
    "n = lasagne.layers.Conv1DLayer(l_in, 20, filter_size=3)  # None x 10 x 28\n",
    "n = lasagne.layers.MaxPool1DLayer(n, 2)  # None x 30 x 14\n",
    "n = lasagne.layers.Conv1DLayer(l_in, 40, filter_size=3)  # None x 20 x 12\n",
    "n = lasagne.layers.MaxPool1DLayer(n, 2)  # None x 60 x 6\n",
    "n = lasagne.layers.Conv1DLayer(l_in, 70, filter_size=3)  # None x 30 x 4\n",
    "n = lasagne.layers.MaxPool1DLayer(n, 2)  # None x 90 x 2\n",
    "n = lasagne.layers.reshape(n, ([0], -1))\n",
    "n = lasagne.layers.DropoutLayer(n, 0.5)\n",
    "n = lasagne.layers.DenseLayer(n, 100)\n",
    "n = lasagne.layers.DenseLayer(n, 1)\n",
    "\n",
    "output = lasagne.layers.get_output(n)\n",
    "params = lasagne.layers.get_all_params(n)\n",
    "\n",
    "correct_energy = output[0::2][0]  # 50\n",
    "corrupt_energy = output[1::2][0]  # 50\n",
    "\n",
    "energy = T.maximum(0, MARGIN + correct_energy - corrupt_energy).mean()\n",
    "updates = lasagne.updates.adam(energy, params)\n",
    "\n",
    "print('Compiling functions ...')\n",
    "forward_fn = theano.function([l_in.input_var], output)\n",
    "train_fn = theano.function([l_in.input_var], energy, updates=updates)\n",
    "test_fn = theano.function([l_in.input_var], energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def energy_fn(txt):\n",
    "    sents = nltk.sent_tokenize(txt)\n",
    "    data = [text2vec(s, GLOVE, SEQ_LENGTH).T[np.newaxis] for s in sents]\n",
    "    return forward_fn(np.concatenate(data, axis=0)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0 48sec\n",
      "1"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "BATCH_SIZE = 50\n",
    "EPOCH_COUNT = 10\n",
    "indices = np.arange(60000)\n",
    "for e in range(EPOCH_COUNT):\n",
    "    epoch_start = time()\n",
    "    np.random.shuffle(indices)\n",
    "    errors = []\n",
    "    for i in xrange(0, indices.shape[0], BATCH_SIZE):\n",
    "        train_sent_idx = [k for k in indices[i:i+BATCH_SIZE]]\n",
    "        train_data = []\n",
    "        for correct_idx in train_sent_idx:\n",
    "            corrupted = corrupt(sentences, pos_tags, correct_idx)\n",
    "            if corrupted:\n",
    "                train_data.append(text2vec(sentences[correct_idx], GLOVE, SEQ_LENGTH).T[np.newaxis])\n",
    "                train_data.append(text2vec(' '.join(corrupted), GLOVE, SEQ_LENGTH).T[np.newaxis])\n",
    "        train_data = np.concatenate(train_data, axis=0)\n",
    "        error = train_fn(train_data)\n",
    "        errors.append(error)\n",
    "#         print('\\t', np.mean(errors[-1000:]))\n",
    "    time_passed = time() - epoch_start\n",
    "    print(e, np.mean(errors), '%.0fsec' % time_passed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1283543537\n",
      "11.7416905774\n",
      "10.3514525111\n",
      "11.0380955383\n"
     ]
    }
   ],
   "source": [
    "v1 = 'the sun is the main source of energy for the water cycle .'\n",
    "v2 = 'fossil fuels is the main source of energy for the water cycle .'\n",
    "v3 = 'clouds is the main source of energy for the water cycle .'\n",
    "v4 = 'the ocean is the main source of energy for the water cycle .'\n",
    "\n",
    "# v1 = 'tension has the greatest effect on aiding the movement of blood through the human body .'\n",
    "# v2 = 'friction has the greatest effect on aiding the movement of blood through the human body .'\n",
    "# v3 = 'density has the greatest effect on aiding the movement of blood through the human body .'\n",
    "# v4 = 'gravity has the greatest effect on aiding the movement of blood through the human body .'\n",
    "\n",
    "print(energy_fn(v1))\n",
    "print(energy_fn(v2))\n",
    "print(energy_fn(v3))\n",
    "print(energy_fn(v4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tries = []\n",
    "\n",
    "with codecs.open(\"/home/marat/Downloads/training_set_merged.tsv\", encoding=\"utf-8\") as f:\n",
    "    for i, l in enumerate(f):\n",
    "        q_id, correct, a1, a2, a3, a4 = l.strip().split(\"\\t\")\n",
    "        energies = [energy_fn(v) for v in [a1, a2, a3, a4]]\n",
    "        guess = \"ABCD\"[np.argmin(energies)]\n",
    "#         print(guess, correct, q_id, zip([a1, a2, a3, a4], energies))\n",
    "        tries.append(guess == correct)\n",
    "#         if i > 10:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25040000000000001"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
