{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, unicode_literals\n",
    "import numpy as np\n",
    "import codecs\n",
    "import random\n",
    "import nltk\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 1.26 s, total: 1min 12s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from spacy.en import English\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA = \"/Users/Pavel/Code/allen-ai-challenge/data/ck12_tokens.txt\"\n",
    "DATA = \"/home/marat/ck12_tokens.txt\"\n",
    "TRAINING_SET_MERGED = \"/home/marat/Downloads/training_set_merged.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GLOVE_D = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GLOVE_FILE = \"/home/marat/data/glove.6B/glove.6B.%dd.txt\" % GLOVE_D\n",
    "GLOVE_FILE = \"/home/marat/data/word2vec.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_dict(fname):\n",
    "    d = {}\n",
    "    with codecs.open(fname, encoding=\"utf-8\") as f:\n",
    "        for row in (line.strip().split() for line in f):\n",
    "            w = row[0]\n",
    "            v = np.array(row[1:], dtype='float32')\n",
    "            assert v.shape == (GLOVE_D,)\n",
    "            d[w] = v\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GLOVE = read_dict(GLOVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(GLOVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def text2vec(text, glove_dict, seq_length, debug=False):\n",
    "#     vecs = []\n",
    "#     for w in text.split():\n",
    "#         try:\n",
    "#             vecs.append(glove_dict[w][np.newaxis, :])\n",
    "#         except KeyError:\n",
    "#             if debug:\n",
    "#                 print(\"%s is not found\" % w)\n",
    "#             continue\n",
    "#     if not vecs:\n",
    "#         print(\"no vector for '%s'\" % text)\n",
    "#         return np.zeros((seq_length, GLOVE_D))\n",
    "    \n",
    "#     rec = np.concatenate(vecs, axis=0).astype('float32')\n",
    "#     if rec.shape[0] > seq_length:\n",
    "#         # trim long sentences\n",
    "#         rec = rec[rec.shape[0] - seq_length:, :]\n",
    "#     elif rec.shape[0] < seq_length:\n",
    "#         # extend short sentences with zeros\n",
    "#         rec = np.vstack([np.zeros((seq_length - rec.shape[0], rec.shape[1])), rec])\n",
    "#     assert rec.shape[0] == seq_length\n",
    "#     return rec\n",
    "\n",
    "def text2vec(text, seq_length, debug=False):\n",
    "    D = 300\n",
    "    vecs = []\n",
    "    for w in text:\n",
    "        vecs.append(w.vector[np.newaxis])\n",
    "\n",
    "    if not vecs:\n",
    "        print(\"no vector for '%s'\" % text)\n",
    "        return np.zeros((seq_length, D), dtype='float32')\n",
    "    \n",
    "    rec = np.concatenate(vecs, axis=0)\n",
    "    if rec.shape[0] > seq_length:\n",
    "        # trim long sentences\n",
    "        rec = rec[rec.shape[0] - seq_length:, :]\n",
    "    elif rec.shape[0] < seq_length:\n",
    "        # extend short sentences with zeros\n",
    "        rec = np.vstack([np.zeros((seq_length - rec.shape[0], rec.shape[1])), rec])\n",
    "    assert rec.shape[0] == seq_length\n",
    "    return rec.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 300)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text2vec(next(nlp(\"hello , die\").sents), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# i=0\n",
    "# sentences = []\n",
    "# with codecs.open(DATA, encoding=\"utf-8\") as f:\n",
    "#     for line in f:\n",
    "#         if u'↓' in line:\n",
    "#             continue\n",
    "# #         i += 1\n",
    "# #         if 63798 < i 63800 :\n",
    "#         sentences.append(line.strip())\n",
    "        \n",
    "# blob = TextBlob(' '.join(sentences))\n",
    "# all_pos_tags = blob.tags        \n",
    "\n",
    "# i = 0\n",
    "# pos_tags = []\n",
    "# for l, line in enumerate(sentences):    \n",
    "#     tags = []\n",
    "#     for word in line.split():\n",
    "# #         if l == 63798:\n",
    "# #         print(word, i, all_pos_tags[i])\n",
    "#         if word.replace(\".\", \"\") == all_pos_tags[i][0].replace(\".\", \"\"):\n",
    "#             tags.append(all_pos_tags[i][1])\n",
    "#             i += 1\n",
    "#         else:\n",
    "#             tags.append('.')\n",
    "            \n",
    "#     pos_tags.append(tags)\n",
    "# #     if l == 63798:\n",
    "# #     print(line, tags)\n",
    "#     break\n",
    "\n",
    "# del all_pos_tags\n",
    "\n",
    "# assert len(sentences) == len(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 38s, sys: 748 ms, total: 1min 39s\n",
      "Wall time: 3min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences = []\n",
    "with codecs.open(DATA, encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if u'↓' in line:\n",
    "            continue\n",
    "        for s in nlp(line.strip()).sents:\n",
    "            sentences.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your body’s first line of defense is like a castle’s moat and walls .\n",
      "walls  NNS & moat  NN -> like  IN\n",
      "* your body\n",
      "* defense\n",
      "* a castle’s moat\n",
      "* walls\n",
      "body is \n",
      "--------------------------------------------------------------------------------\n",
      "the first line also includes tears , mucus , cilia , stomach acid , urine flow , and friendly bacteria .\n",
      "mucus  NN & tears  NNS -> includes  VBZ\n",
      "cilia  NN & mucus  NN -> tears  NNS\n",
      "acid  NN & cilia  NN -> mucus  NN\n",
      "flow  NN & acid  NN -> cilia  NN\n",
      "bacteria  NNS & flow  NN -> acid  NN\n",
      "* the first line\n",
      "* tears\n",
      "* mucus\n",
      "* cilia\n",
      "* stomach acid\n",
      "* urine flow\n",
      "* friendly bacteria\n",
      "line  includes \n",
      "--------------------------------------------------------------------------------\n",
      "it forms a physical barrier between the body and the outside world .\n",
      "world  NN & body  NN -> between  IN\n",
      "* it\n",
      "* a physical barrier\n",
      "* the body\n",
      "* the outside world\n",
      "it  forms \n",
      "--------------------------------------------------------------------------------\n",
      "the outer layer is tough and waterproof .\n",
      "waterproof  JJ & tough  JJ -> is  VBZ\n",
      "* the outer layer\n",
      "layer  is \n",
      "--------------------------------------------------------------------------------\n",
      "the mouth and nose are not lined with skin .\n",
      "nose  NN & mouth  NN -> lined  VBN\n",
      "* the mouth\n",
      "* nose\n",
      "* skin\n",
      "mouth  lined \n",
      "--------------------------------------------------------------------------------\n",
      "other organs that are exposed to the outside world , including the lungs and stomach , are also lined with mucous membranes .\n",
      "stomach  NN & lungs  NNS -> including  VBG\n",
      "* other organs\n",
      "* the outside world\n",
      "* the lungs\n",
      "* stomach\n",
      "* mucous membranes\n",
      "that  lined \n",
      "--------------------------------------------------------------------------------\n",
      "mucous membranes are not tough like skin , but they have other defenses .\n",
      "have  VBP & are  VBP -> are  VBP\n",
      "* mucous membranes\n",
      "* skin\n",
      "* they\n",
      "* other defenses\n",
      "they  are \n",
      "--------------------------------------------------------------------------------\n",
      "they move in waves and sweep mucus and trapped pathogens toward body openings .\n",
      "sweep  VB & move  VBP -> move  VBP\n",
      "* they\n",
      "* waves\n",
      "* mucus\n",
      "* trapped pathogens\n",
      "* body openings\n",
      "they  move \n",
      "--------------------------------------------------------------------------------\n",
      "when you clear your throat or blow your nose , you remove mucus and pathogens from your body .\n",
      "blow  VB & clear  VBP -> remove  VBP\n",
      "pathogens  NNS & mucus  NN -> remove  VBP\n",
      "* you\n",
      "* your throat\n",
      "* your nose\n",
      "* you\n",
      "* mucus\n",
      "* pathogens\n",
      "* your body\n",
      "you  remove \n",
      "--------------------------------------------------------------------------------\n",
      "for example , mucus , sweat , tears , and saliva contain enzymes called lysozymes that kill pathogens .\n",
      "sweat  NN & mucus  NN -> contain  VBP\n",
      "tears  NNS & sweat  NN -> mucus  NN\n",
      "saliva  NN & tears  NNS -> sweat  NN\n",
      "* example\n",
      "* mucus\n",
      "* sweat\n",
      "* tears\n",
      "* saliva\n",
      "* enzymes\n",
      "* pathogens\n",
      "that  contain \n",
      "--------------------------------------------------------------------------------\n",
      "this acid kills most pathogens that enter the stomach in food or water .\n",
      "water  NN & food  NN -> in  IN\n",
      "* this acid\n",
      "* most pathogens\n",
      "* the stomach\n",
      "* food\n",
      "* water\n",
      "that  kills \n",
      "--------------------------------------------------------------------------------\n",
      "urine is also acidic , so few pathogens can grow in it .\n",
      "grow  VB & is  VBZ -> is  VBZ\n",
      "* urine\n",
      "* few pathogens\n",
      "* it\n",
      "pathogens  is \n",
      "--------------------------------------------------------------------------------\n",
      "you are not aware of them , but your skin is covered by millions ( or more ! )\n",
      "covered  VBN & are  VBP -> are  VBP\n",
      "* you\n",
      "* them\n",
      "* your skin\n",
      "* millions\n",
      "skin  are \n",
      "--------------------------------------------------------------------------------\n",
      "they compete with harmful bacteria for food and space .\n",
      "space  NN & food  NN -> for  IN\n",
      "* they\n",
      "* harmful bacteria\n",
      "* food\n",
      "* space\n",
      "they  compete \n",
      "--------------------------------------------------------------------------------\n",
      "this prevents the harmful bacteria from multiplying and making you sick .\n",
      "making  VBG & multiplying  VBG -> from  IN\n",
      "* the harmful bacteria\n",
      "* you\n",
      "you  prevents \n",
      "--------------------------------------------------------------------------------\n",
      "your body’s first line of defense includes the skin and other barriers that keep pathogens out of your body .\n",
      "barriers  NNS & skin  NN -> includes  VBZ\n",
      "* your body\n",
      "* defense\n",
      "* the skin\n",
      "* other barriers\n",
      "* pathogens\n",
      "* your body\n",
      "that  includes \n",
      "--------------------------------------------------------------------------------\n",
      "did you notice redness and swelling near the injury ?\n",
      "swelling  VBG & notice  VB -> notice  VB\n",
      "* you\n",
      "* redness\n",
      "* the injury\n",
      "you  notice \n",
      "--------------------------------------------------------------------------------\n",
      "if bacteria enter the skin through a scrape , the area may become red , warm , and painful .\n",
      "warm  JJ & red  JJ -> become  VB\n",
      "painful  JJ & warm  JJ -> red  JJ\n",
      "* bacteria\n",
      "* the skin\n",
      "* a scrape\n",
      "* the area\n",
      "area  become \n",
      "--------------------------------------------------------------------------------\n",
      "inflammation is one way the body reacts to infections or injuries .\n",
      "injuries  NNS & infections  NNS -> to  IN\n",
      "* inflammation\n",
      "* one way\n",
      "* the body\n",
      "* infections\n",
      "* injuries\n",
      "body  is \n",
      "--------------------------------------------------------------------------------\n",
      "inflammation is caused by chemicals that are released when skin or other tissues are damaged .\n",
      "tissues  NNS & skin  NN -> damaged  VBN\n",
      "* inflammation\n",
      "* chemicals\n",
      "* skin\n",
      "* other tissues\n",
      "skin  caused \n",
      "--------------------------------------------------------------------------------\n",
      "the chemicals cause nearby blood vessels to dilate , or expand .\n",
      "expand  VB & dilate  VB -> cause  VBP\n",
      "* chemicals\n",
      "* nearby blood vessels\n",
      "vessels  cause \n",
      "--------------------------------------------------------------------------------\n",
      "this increases blood flow to the damaged area , which makes the area red and slightly warm .\n",
      "warm  JJ & red  JJ -> makes  VBZ\n",
      "* blood flow\n",
      "* the damaged area\n",
      "* the area\n",
      "area  increases \n",
      "--------------------------------------------------------------------------------\n",
      "the chemicals also attract white blood cells called neutrophils to the wound and cause them to leak out of blood vessels into the damaged tissue .\n",
      "cause  VB & attract  VBP -> attract  VBP\n",
      "* the chemicals\n",
      "* white blood cells\n",
      "* the wound\n",
      "* them\n",
      "* blood vessels\n",
      "* the damaged tissue\n",
      "them  attract \n",
      "--------------------------------------------------------------------------------\n",
      "they surround the pathogens and destroy them .\n",
      "destroy  VB & surround  VBP -> surround  VBP\n",
      "* they\n",
      "* the pathogens\n",
      "* them\n",
      "they  surround \n",
      "--------------------------------------------------------------------------------\n",
      "sometimes it is said that the phagocyte engulfs the pathogen , and then destroys it .\n",
      "destroys  VBZ & engulfs  VBZ -> said  VBN\n",
      "* it\n",
      "* phagocyte\n",
      "* the pathogen\n",
      "* it\n",
      "phagocyte  said \n",
      "--------------------------------------------------------------------------------\n",
      "most bacteria and viruses that infect people reproduce fastest at this temperature .\n",
      "viruses  NNS & bacteria  NNS -> bacteria  NNS\n",
      "* viruses\n",
      "* people\n",
      "* this temperature\n",
      "people  bacteria \n",
      "--------------------------------------------------------------------------------\n",
      "if pathogens get through the body’s first two lines of defense , a third line of defense takes over .\n",
      "takes  VBZ & ’s  VBD -> ’s  VBD\n",
      "* pathogens\n",
      "* the body\n",
      "* first two lines\n",
      "* defense\n",
      "* a third line\n",
      "* defense\n",
      "line  ’s \n",
      "--------------------------------------------------------------------------------\n",
      "it is called an immune response , and is a specific type of response .\n",
      "is  VBZ & called  VBN -> called  VBN\n",
      "* it\n",
      "* a specific type\n",
      "* response\n",
      "it  called \n",
      "--------------------------------------------------------------------------------\n",
      "they include several lymph organs , lymph vessels , lymph , and lymph nodes .\n",
      "vessels  NNS & organs  NNS -> include  VBP\n",
      "lymph  NN & vessels  NNS -> organs  NNS\n",
      "nodes  NNS & lymph  NN -> vessels  NNS\n",
      "* they\n",
      "* several lymph organs\n",
      "* lymph vessels\n",
      "* lymph\n",
      "* lymph nodes\n",
      "they  include \n",
      "--------------------------------------------------------------------------------\n",
      "the lymph organs are the red bone marrow , tonsils , spleen , and thymus gland .\n",
      "tonsils  NNS & marrow  NN -> are  VBP\n",
      "spleen  NN & tonsils  NNS -> marrow  NN\n",
      "gland  NN & spleen  NN -> tonsils  NNS\n",
      "* the lymph organs\n",
      "* the red bone marrow\n",
      "* tonsils\n",
      "* spleen\n",
      "* thymus gland\n",
      "organs  are \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# from spacy import parts_of_speech as pos\n",
    "# from spacy.util import DEP\n",
    "# # print(sentences[0])\n",
    "# for i, s in enumerate(sentences[10000:]):\n",
    "#     if i >= 100:\n",
    "#         break\n",
    "# #     if i != 7:\n",
    "# #         continue\n",
    "#     has_conj = False\n",
    "#     for w in s:\n",
    "#         if 'conj' in w.dep_:\n",
    "#             has_conj = True\n",
    "#             break\n",
    "#     if not has_conj:\n",
    "#         continue\n",
    "    \n",
    "\n",
    "#     print(s.text)\n",
    "# #     s = next(nlp(s).sents)\n",
    "\n",
    "#     subj = None\n",
    "#     for w in s:\n",
    "#         if 'nsubj' in w.dep_:\n",
    "#             subj = w\n",
    "# #         print('\\t', w.text, w.dep_, w.tag_)\n",
    "\n",
    "#     for w in s:\n",
    "#         if 'conj' in w.dep_:\n",
    "#             print(w, w.tag_, '&', w.head, w.head.tag_, '->', w.head.head, w.head.head.tag_)\n",
    "\n",
    "#     for n in s.doc.noun_chunks:\n",
    "#         print('*', n)\n",
    "        \n",
    "\n",
    "#     print(subj, s.root)\n",
    "#     print('-'*80)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CC Coordinating conjunction\n",
    "CD Cardinal number\n",
    "DT Determiner\n",
    "EX Existential there\n",
    "FW Foreign word\n",
    "IN Preposition or subordinating conjunction\n",
    "JJ Adjective\n",
    "JJR Adjective, comparative\n",
    "JJS Adjective, superlative\n",
    "LS List item marker\n",
    "MD Modal\n",
    "NN Noun, singular or mass\n",
    "NNS Noun, plural\n",
    "NNP Proper noun, singular\n",
    "NNPS Proper noun, plural\n",
    "PDT Predeterminer\n",
    "POS Possessive ending\n",
    "PRP Personal pronoun\n",
    "PRP$ Possessive pronoun\n",
    "RB Adverb\n",
    "RBR Adverb, comparative\n",
    "RBS Adverb, superlative\n",
    "RP Particle\n",
    "SYM Symbol\n",
    "TO to\n",
    "UH Interjection\n",
    "VB Verb, base form\n",
    "VBD Verb, past tense\n",
    "VBG Verb, gerund or present participle\n",
    "VBN Verb, past participle\n",
    "VBP Verb, non­3rd person singular present\n",
    "VBZ Verb, 3rd person singular present\n",
    "WDT Wh­determiner\n",
    "WP Wh­pronoun\n",
    "WP$ Possessive wh­pronoun\n",
    "WRB Wh­adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CORRUPT_WINDOW = 10\n",
    "# def corrupt(sentences, index):\n",
    "#     s = sentences[index]\n",
    "#     noun_indices = [i for i, w in enumerate(s) if 'NN' in w.tag_]\n",
    "#     if not noun_indices:\n",
    "#         return None\n",
    "#     noun_to_replace_index = random.choice(noun_indices)\n",
    "#     all_donor_indices = range(max(0, index-CORRUPT_WINDOW), index) + \\\n",
    "#                         range(index+1, min(len(sentences), index+CORRUPT_WINDOW+1))\n",
    "#     donor_index = random.choice(all_donor_indices)\n",
    "#     all_nouns_to_insert = [w for w in sentences[donor_index] if 'NN' in w.tag_]\n",
    "#     if not all_nouns_to_insert:\n",
    "#         return None\n",
    "#     noun_to_insert = random.choice(all_nouns_to_insert)\n",
    "    \n",
    "#     return next(nlp(s[:noun_to_replace_index].text + ' ' + noun_to_insert.text + ' ' \n",
    "#                     + s[noun_to_replace_index+1:].text).sents)\n",
    "\n",
    "def corrupt(sentences, index):\n",
    "    s = sentences[index]\n",
    "    noun_chunks = list(s.doc.noun_chunks)\n",
    "    if not noun_chunks:\n",
    "        return None\n",
    "    noun_chunk_to_replace = random.choice(noun_chunks)\n",
    "    \n",
    "    all_donor_indices = range(max(0, index-CORRUPT_WINDOW), index) + \\\n",
    "                        range(index+1, min(len(sentences), index+CORRUPT_WINDOW+1))\n",
    "    donor_index = random.choice(all_donor_indices)\n",
    "    all_noun_chunks_to_insert = list(sentences[donor_index].doc.noun_chunks)\n",
    "    if not all_noun_chunks_to_insert:\n",
    "        return None\n",
    "    np_to_insert = random.choice(all_noun_chunks_to_insert)\n",
    "    \n",
    "    new_text = s[:noun_chunk_to_replace.start].text + ' ' + np_to_insert.text + ' ' \\\n",
    "                    + s[noun_chunk_to_replace.end:].text\n",
    "    \n",
    "    return next(nlp(new_text).sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 37s, sys: 1.25 s, total: 1min 38s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for c in range(len(sentences)):\n",
    "    text2vec(sentences[c], corrupt(sentences, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling functions ...\n",
      "CPU times: user 2.4 s, sys: 44 ms, total: 2.44 s\n",
      "Wall time: 4.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "theano.config.floatX = 'float32'\n",
    "\n",
    "SEQ_LENGTH = 30\n",
    "MARGIN = 1\n",
    "\n",
    "l_in = lasagne.layers.InputLayer(shape=(None, GLOVE_D, SEQ_LENGTH))\n",
    "n = lasagne.layers.Conv1DLayer(l_in, 20, filter_size=3)  # None x 10 x 28\n",
    "n = lasagne.layers.MaxPool1DLayer(n, 2)  # None x f x 14\n",
    "n = lasagne.layers.Conv1DLayer(l_in, 30, filter_size=3)  # None x 20 x 12\n",
    "n = lasagne.layers.MaxPool1DLayer(n, 2)  # None x f x 6\n",
    "n = lasagne.layers.Conv1DLayer(l_in, 50, filter_size=3)  # None x 30 x 4\n",
    "n = lasagne.layers.MaxPool1DLayer(n, 2)  # None x f x 2\n",
    "n = lasagne.layers.reshape(n, ([0], -1))\n",
    "# n = lasagne.layers.DropoutLayer(n, 0.5)\n",
    "n = lasagne.layers.DenseLayer(n, 100)\n",
    "n = lasagne.layers.DenseLayer(n, 1)\n",
    "\n",
    "output = lasagne.layers.get_output(n)\n",
    "params = lasagne.layers.get_all_params(n)\n",
    "\n",
    "correct_energy = output[0::2][0]  # 50\n",
    "corrupt_energy = output[1::2][0]  # 50\n",
    "\n",
    "energy = T.maximum(0, MARGIN + correct_energy - corrupt_energy).mean()\n",
    "updates = lasagne.updates.adam(energy, params)\n",
    "\n",
    "print('Compiling functions ...')\n",
    "forward_fn = theano.function([l_in.input_var], output)\n",
    "train_fn = theano.function([l_in.input_var], energy, updates=updates)\n",
    "test_fn = theano.function([l_in.input_var], energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def energy_fn(txt):\n",
    "    sents = nlp(txt).sents\n",
    "    data = [text2vec(s, SEQ_LENGTH).T[np.newaxis] for s in sents]\n",
    "    return forward_fn(np.concatenate(data, axis=0)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0 24.0% 418s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-226-2b2517773d27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'BATCH_SIZE = 50\\nEPOCH_COUNT = 10\\nindices = np.arange(len(sentences))\\nfor e in range(EPOCH_COUNT):\\n    epoch_start = time()\\n    \\n    tries = []\\n    with codecs.open(TRAINING_SET_MERGED, encoding=\"utf-8\") as f:\\n        for i, l in enumerate(f):\\n            q_id, correct, a1, a2, a3, a4 = l.strip().split(\"\\\\t\")\\n            energies = [energy_fn(v) for v in [a1, a2, a3, a4]]\\n            guess = \"ABCD\"[np.argmin(energies)]\\n            tries.append(guess == correct)   \\n    \\n    np.random.shuffle(indices)\\n    errors = []\\n    for i in xrange(0, indices.shape[0], BATCH_SIZE):\\n        train_sent_idx = [k for k in indices[i:i+BATCH_SIZE]]\\n        train_data = []\\n        for correct_idx in train_sent_idx:\\n            corrupted = corrupt(sentences, correct_idx)\\n            if corrupted:\\n                train_data.append(text2vec(sentences[correct_idx], SEQ_LENGTH).T[np.newaxis])\\n                train_data.append(text2vec(corrupted, SEQ_LENGTH).T[np.newaxis])\\n        train_data = np.concatenate(train_data, axis=0)\\n        error = train_fn(train_data)\\n        errors.append(error)\\n                   \\n    time_passed = time() - epoch_start\\n    print(e, np.mean(errors), \\'%.1f%%\\' % (np.mean(tries) * 100),\\'%.0fs\\' % time_passed)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/marat/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2291\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2292\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2293\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2294\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/marat/.local/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/marat/.local/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/marat/.local/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1165\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1167\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1168\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/home/marat/.local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "BATCH_SIZE = 50\n",
    "EPOCH_COUNT = 10\n",
    "indices = np.arange(len(sentences))\n",
    "for e in range(EPOCH_COUNT):\n",
    "    epoch_start = time()\n",
    "    \n",
    "    tries = []\n",
    "    with codecs.open(TRAINING_SET_MERGED, encoding=\"utf-8\") as f:\n",
    "        for i, l in enumerate(f):\n",
    "            q_id, correct, a1, a2, a3, a4 = l.strip().split(\"\\t\")\n",
    "            energies = [energy_fn(v) for v in [a1, a2, a3, a4]]\n",
    "            guess = \"ABCD\"[np.argmin(energies)]\n",
    "            tries.append(guess == correct)   \n",
    "    \n",
    "    np.random.shuffle(indices)\n",
    "    errors = []\n",
    "    for i in xrange(0, indices.shape[0], BATCH_SIZE):\n",
    "        train_sent_idx = [k for k in indices[i:i+BATCH_SIZE]]\n",
    "        train_data = []\n",
    "        for correct_idx in train_sent_idx:\n",
    "            corrupted = corrupt(sentences, correct_idx)\n",
    "            if corrupted:\n",
    "                train_data.append(text2vec(sentences[correct_idx], SEQ_LENGTH).T[np.newaxis])\n",
    "                train_data.append(text2vec(corrupted, SEQ_LENGTH).T[np.newaxis])\n",
    "        train_data = np.concatenate(train_data, axis=0)\n",
    "        error = train_fn(train_data)\n",
    "        errors.append(error)\n",
    "                   \n",
    "    time_passed = time() - epoch_start\n",
    "    print(e, np.mean(errors), '%.1f%%' % (np.mean(tries) * 100),'%.0fs' % time_passed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v1 = 'the sun is the main source of energy for the water cycle .'\n",
    "v2 = 'fossil fuels is the main source of energy for the water cycle .'\n",
    "v3 = 'clouds is the main source of energy for the water cycle .'\n",
    "v4 = 'the ocean is the main source of energy for the water cycle .'\n",
    "\n",
    "# v1 = 'tension has the greatest effect on aiding the movement of blood through the human body .'\n",
    "# v2 = 'friction has the greatest effect on aiding the movement of blood through the human body .'\n",
    "# v3 = 'density has the greatest effect on aiding the movement of blood through the human body .'\n",
    "# v4 = 'gravity has the greatest effect on aiding the movement of blood through the human body .'\n",
    "\n",
    "print(energy_fn(v1))\n",
    "print(energy_fn(v2))\n",
    "print(energy_fn(v3))\n",
    "print(energy_fn(v4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tries = []\n",
    "\n",
    "with codecs.open(TRAINING_SET_MERGED, encoding=\"utf-8\") as f:\n",
    "    for i, l in enumerate(f):\n",
    "        q_id, correct, a1, a2, a3, a4 = l.strip().split(\"\\t\")\n",
    "        energies = [energy_fn(v) for v in [a1, a2, a3, a4]]\n",
    "        guess = \"ABCD\"[np.argmin(energies)]\n",
    "#         print(guess, correct, q_id, zip([a1, a2, a3, a4], energies))\n",
    "        tries.append(guess == correct)\n",
    "#         if i > 10:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(tries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
