{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, unicode_literals\n",
    "import six\n",
    "import os\n",
    "from os.path import join\n",
    "import json\n",
    "from codecs import open\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = join(os.environ['HOME'], 'data/allen-ai-challenge')\n",
    "\n",
    "TRAINING = True\n",
    "LUCENE_VEC_DIM = 7\n",
    "\n",
    "TRAINING_SET = join(DATA_DIR, 'training_set.tsv')\n",
    "\n",
    "if TRAINING:\n",
    "    LUCENE_FILE = join(DATA_DIR, 'features', 'lucene_vecs%d.tsv' % LUCENE_VEC_DIM)\n",
    "    W2V_FILE = join(DATA_DIR, 'features', 'w2f.tsv')\n",
    "else:\n",
    "    LUCENE_FILE = join(DATA_DIR, 'features', 'lucene_vecs%d_submission.tsv' % LUCENE_VEC_DIM)\n",
    "    W2V_FILE = join(DATA_DIR, 'features', 'w2f_validate.tsv')\n",
    "\n",
    "SUMBISSION_FILE = join(DATA_DIR, 'submissions', 'vec25_gamma222.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_x = []\n",
    "all_y = []\n",
    "all_qid = []\n",
    "with open(LUCENE_FILE, encoding='utf8') as f:\n",
    "    for row in (line.strip().split('\\t') for line in f):\n",
    "        all_qid.append(row[0])\n",
    "        correct = row[1]\n",
    "        vecs = np.vstack([np.fromstring(r, sep=';') for r in row[2:6]])\n",
    "        \n",
    "        all_x.append(vecs)\n",
    "        y_vec = np.zeros(4, dtype=int)\n",
    "        if correct in 'ABCD':\n",
    "             y_vec['ABCD'.index(correct)] = 1\n",
    "        all_y.append(y_vec)\n",
    "all_x = np.array(all_x)\n",
    "all_y = np.array(all_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 4, 7)\n",
      "(2500, 4)\n"
     ]
    }
   ],
   "source": [
    "idx_train, idx_valid = next(iter(KFold(all_x.shape[0], 5, shuffle=True)))\n",
    "print(all_x.shape)\n",
    "print(W2V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "D = all_x.shape[2]\n",
    "\n",
    "L2_REG = 1e+0\n",
    "\n",
    "def l2_to1(x):\n",
    "    return T.mean((x-1)**2)\n",
    "\n",
    "lin = lasagne.layers.InputLayer((None, D))  # (4b, 10)\n",
    "n = lasagne.layers.DenseLayer(lin, 1, b=None, W=lasagne.init.Constant(1),\n",
    "                              nonlinearity=lasagne.nonlinearities.elu)  # (4b, 1)\n",
    "n = lasagne.layers.ReshapeLayer(n, (-1, 4))  # (b, 4)\n",
    "\n",
    "t_raw_output = lasagne.layers.get_output(n)\n",
    "\n",
    "n1 = lasagne.layers.NonlinearityLayer(n, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "t_output = lasagne.layers.get_output(n1)\n",
    "params = lasagne.layers.get_all_params(n1)\n",
    "\n",
    "var_targets = T.imatrix()\n",
    "t_nll = lasagne.objectives.categorical_crossentropy(t_output, var_targets).mean()\n",
    "t_reg_loss = lasagne.regularization.regularize_network_params(n, l2_to1) * L2_REG\n",
    "t_acc = lasagne.objectives.categorical_accuracy(t_output, var_targets).mean()\n",
    "updates = lasagne.updates.adam(t_nll + t_reg_loss, params)\n",
    "# updates = lasagne.updates.nesterov_momentum(t_nll + t_reg_loss, params, learning_rate=1e-3, momentum=0.9)\n",
    "\n",
    "train_fn = theano.function([lin.input_var, var_targets], t_nll, updates=updates)\n",
    "cost_fn = theano.function([lin.input_var, var_targets], t_nll)\n",
    "acc_fn = theano.function([lin.input_var, var_targets], t_acc)\n",
    "forward_fn = theano.function([lin.input_var], t_raw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.9117148796 0.422\n",
      "1 2.88829792275 0.416\n",
      "2 2.86463200064 0.422\n",
      "3 2.84142113789 0.418\n",
      "4 2.81845641181 0.42\n",
      "5 2.79545273099 0.42\n",
      "6 2.77246809464 0.42\n",
      "7 2.74998027711 0.418\n",
      "8 2.72728790966 0.416\n",
      "9 2.70485192273 0.418\n",
      "10 2.68290658255 0.418\n",
      "11 2.66116309546 0.422\n",
      "12 2.63937378165 0.414\n",
      "13 2.61780404743 0.42\n",
      "14 2.59673432093 0.416\n",
      "15 2.57543297601 0.42\n",
      "16 2.55471316998 0.416\n",
      "17 2.53386949822 0.416\n",
      "18 2.51365250835 0.416\n",
      "19 2.49362733553 0.42\n",
      "20 2.47283128348 0.422\n",
      "21 2.45286879693 0.416\n",
      "22 2.43327896171 0.422\n",
      "23 2.41382210127 0.42\n",
      "24 2.39400823186 0.418\n",
      "25 2.37483511443 0.42\n",
      "26 2.35606095014 0.418\n",
      "27 2.33748595302 0.42\n",
      "28 2.31874722661 0.42\n",
      "29 2.30032859339 0.418\n",
      "30 2.28253668408 0.42\n",
      "31 2.26472407696 0.418\n",
      "32 2.24670253479 0.416\n",
      "33 2.22925626374 0.414\n",
      "34 2.21222848987 0.422\n",
      "35 2.1956607717 0.422\n",
      "36 2.17877865583 0.416\n",
      "37 2.16191787489 0.414\n",
      "38 2.14584700503 0.416\n",
      "39 2.12957756895 0.414\n",
      "40 2.11380694518 0.422\n",
      "41 2.09804977513 0.418\n",
      "42 2.08248168357 0.418\n",
      "43 2.06684932404 0.416\n",
      "44 2.05227113965 0.418\n",
      "45 2.03738788046 0.418\n",
      "46 2.02321834158 0.416\n",
      "47 2.00859408503 0.42\n",
      "48 1.9944672129 0.418\n",
      "49 1.98079757444 0.418\n",
      "50 1.96745324502 0.418\n",
      "51 1.95375116388 0.42\n",
      "52 1.94038473199 0.414\n",
      "53 1.927554042 0.422\n",
      "54 1.91472240256 0.414\n",
      "55 1.90249074271 0.418\n",
      "56 1.89018460675 0.416\n",
      "57 1.87787548419 0.418\n",
      "58 1.86608117055 0.422\n",
      "59 1.85408420825 0.42\n",
      "60 1.84299689836 0.418\n",
      "61 1.83224308332 0.418\n",
      "62 1.82108463738 0.418\n",
      "63 1.81042222439 0.418\n",
      "64 1.79967355482 0.412\n",
      "65 1.78910802739 0.414\n",
      "66 1.77928125969 0.42\n",
      "67 1.76942594865 0.412\n",
      "68 1.75965482941 0.414\n",
      "69 1.75016432345 0.414\n",
      "70 1.74111100284 0.416\n",
      "71 1.73212854565 0.42\n",
      "72 1.72321874266 0.414\n",
      "73 1.71489099272 0.416\n",
      "74 1.70682059698 0.422\n",
      "75 1.69853267944 0.42\n",
      "76 1.69083460824 0.418\n",
      "77 1.68295351709 0.414\n",
      "78 1.67494231594 0.414\n",
      "79 1.66792133717 0.416\n",
      "80 1.66037540767 0.412\n",
      "81 1.65342481695 0.412\n",
      "82 1.64660099341 0.414\n",
      "83 1.64078305233 0.418\n",
      "84 1.6337912995 0.414\n",
      "85 1.62788025691 0.416\n",
      "86 1.62184154046 0.418\n",
      "87 1.61585678722 0.418\n",
      "88 1.61018542374 0.414\n",
      "89 1.60457993892 0.414\n",
      "90 1.59964781139 0.414\n",
      "91 1.59408860338 0.418\n",
      "92 1.58997744246 0.418\n",
      "93 1.58498675936 0.414\n",
      "94 1.58032533657 0.418\n",
      "95 1.57553307394 0.416\n",
      "96 1.57128040155 0.414\n",
      "97 1.56737693893 0.41\n",
      "98 1.56296059335 0.412\n",
      "99 1.55886960441 0.414\n",
      "100 1.55559255154 0.414\n",
      "101 1.55200436676 0.418\n",
      "102 1.54870959853 0.414\n",
      "103 1.54468455928 0.414\n",
      "104 1.541865227 0.408\n",
      "105 1.53838519104 0.414\n",
      "106 1.53582155809 0.408\n",
      "107 1.53256260808 0.408\n",
      "108 1.52941727596 0.412\n",
      "109 1.52683311676 0.414\n",
      "110 1.52446976444 0.41\n",
      "111 1.52205933977 0.41\n",
      "112 1.51930534515 0.418\n",
      "113 1.51737371473 0.412\n",
      "114 1.51497944031 0.414\n",
      "115 1.51275647896 0.41\n",
      "116 1.51093428903 0.41\n",
      "117 1.50893355628 0.408\n",
      "118 1.50714255482 0.416\n",
      "119 1.50512054999 0.418\n",
      "120 1.5032788205 0.408\n",
      "121 1.5018836917 0.41\n",
      "122 1.50019924439 0.414\n",
      "123 1.49863253025 0.416\n",
      "124 1.49720909778 0.404\n",
      "125 1.49582870628 0.406\n",
      "126 1.49419930368 0.41\n",
      "127 1.49317046179 0.41\n",
      "128 1.49197997114 0.404\n",
      "129 1.49062613196 0.408\n",
      "130 1.48944198178 0.412\n",
      "131 1.48822864897 0.41\n",
      "132 1.48716672171 0.412\n",
      "133 1.48673693761 0.414\n",
      "134 1.48573221845 0.41\n",
      "135 1.4843981466 0.408\n",
      "136 1.48361695679 0.414\n",
      "137 1.48247098278 0.412\n",
      "138 1.48182030698 0.416\n",
      "139 1.48122491258 0.41\n",
      "140 1.48038523973 0.412\n",
      "141 1.47964048098 0.412\n",
      "142 1.47896753237 0.414\n",
      "143 1.47802138693 0.414\n",
      "144 1.47747926839 0.414\n",
      "145 1.47747809316 0.412\n",
      "146 1.47658668096 0.41\n",
      "147 1.47543380979 0.416\n",
      "148 1.47515736537 0.414\n",
      "149 1.47438803338 0.412\n",
      "150 1.4741093101 0.418\n",
      "151 1.47422592364 0.416\n",
      "152 1.47339616024 0.41\n",
      "153 1.4728443834 0.41\n",
      "154 1.47255169641 0.414\n",
      "155 1.47247047164 0.416\n",
      "156 1.47232011446 0.414\n",
      "157 1.47180360655 0.416\n",
      "158 1.47175314552 0.414\n",
      "159 1.47116028287 0.412\n",
      "160 1.4706506165 0.41\n",
      "161 1.47016231639 0.414\n",
      "162 1.47005153401 0.412\n",
      "163 1.46965815669 0.414\n",
      "164 1.46917805102 0.416\n",
      "165 1.46908179045 0.412\n",
      "166 1.46822086954 0.408\n",
      "167 1.46806339568 0.412\n",
      "168 1.46851840768 0.412\n",
      "169 1.46811464688 0.41\n",
      "170 1.46796376979 0.408\n",
      "171 1.46754375264 0.41\n",
      "172 1.46750951603 0.408\n",
      "173 1.46762749182 0.412\n",
      "174 1.46695477559 0.408\n",
      "175 1.46725874032 0.416\n",
      "176 1.46710374599 0.41\n",
      "177 1.46704903349 0.406\n",
      "178 1.46688023243 0.416\n",
      "179 1.46661629463 0.414\n",
      "180 1.46644576719 0.408\n",
      "181 1.46577773091 0.41\n",
      "182 1.46543377502 0.41\n",
      "183 1.46616537594 0.414\n",
      "184 1.46545646193 0.406\n",
      "185 1.46543638022 0.41\n",
      "186 1.4651058214 0.412\n",
      "187 1.46597766756 0.41\n",
      "188 1.46522848618 0.406\n",
      "189 1.46501988915 0.41\n",
      "190 1.46507010574 0.408\n",
      "191 1.46507107802 0.412\n",
      "192 1.46476336343 0.41\n",
      "193 1.46496646838 0.408\n",
      "194 1.46447155134 0.412\n",
      "195 1.46459147255 0.414\n",
      "196 1.46426502718 0.41\n",
      "197 1.46418209893 0.408\n",
      "198 1.46435463432 0.406\n",
      "199 1.46448938254 0.412\n"
     ]
    }
   ],
   "source": [
    "def randomize(x, y, randomize=True):\n",
    "    new_x = np.zeros((x.shape[0] * 4, x.shape[2]))\n",
    "    new_y = np.zeros_like(y)\n",
    "    for i in range(x.shape[0]):\n",
    "        keys = np.arange(4)\n",
    "        if randomize:\n",
    "            np.random.shuffle(keys)\n",
    "        for j, k in enumerate(keys):\n",
    "            new_x[i*4 + k] = x[i, j]\n",
    "            new_y[i, k] = y[i, j]\n",
    "    return new_x, new_y.astype('int32')\n",
    "\n",
    "BATCH = 200\n",
    "EPOCHS = 200\n",
    "accuracies = [0]\n",
    "for e in range(EPOCHS):\n",
    "    np.random.shuffle(idx_train)\n",
    "    for i in range(0, idx_train.shape[0], BATCH):\n",
    "        keys = idx_train[i:i+BATCH]\n",
    "        batch_x = all_x[keys]\n",
    "        batch_y = all_y[keys]\n",
    "        bx, by = randomize(batch_x, batch_y)\n",
    "        loss = train_fn(bx, by)\n",
    "#         print(loss)\n",
    "    bx, by = randomize(all_x[idx_valid], all_y[idx_valid])\n",
    "    acc = acc_fn(bx, by)\n",
    "    print(e, cost_fn(bx, by), acc)\n",
    "#     if accuracies[-1] > acc + 0.005 and acc > accuracies[1]:\n",
    "#         break\n",
    "#     accuracies.append(acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.81096655],\n",
       "       [ 0.64290876],\n",
       "       [ 0.49371577],\n",
       "       [ 0.36486337],\n",
       "       [ 0.25365207],\n",
       "       [ 0.15816062],\n",
       "       [ 0.07998841]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[0].get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.412)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward_fn(bx)[0], by[0]\n",
    "acc_fn(bx, by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.4644893825356606)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_fn(bx, by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# W = params[0].get_value()[:,0]\n",
    "# # W = np.ones_like(W)\n",
    "# # W[0] = 2\n",
    "# print(W)\n",
    "\n",
    "def norm_softmax(data):\n",
    "    s = data.sum(axis=1, keepdims=True)\n",
    "    normalized = data/s\n",
    "    exps = np.exp(normalized)\n",
    "    return exps / exps.sum(axis=1, keepdims=True) \n",
    "\n",
    "def softmax(data):\n",
    "    exps = np.exp(data)\n",
    "    return exps / exps.sum(axis=1, keepdims=True)\n",
    "\n",
    "# def softmax(x):\n",
    "#     e_x = np.exp(x - x.max(axis=1, keepdims=True))\n",
    "#     return e_x / e_x.sum(axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "bx, by = randomize(all_x[idx_valid], all_y[idx_valid], randomize=False)\n",
    "\n",
    "lucene_output = forward_fn(bx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 Overall accuracy 0.372\n",
      "0.010101010101 Overall accuracy 0.396\n",
      "0.020202020202 Overall accuracy 0.396\n",
      "0.030303030303 Overall accuracy 0.41\n",
      "0.040404040404 Overall accuracy 0.41\n",
      "0.0505050505051 Overall accuracy 0.418\n",
      "0.0606060606061 Overall accuracy 0.422\n",
      "0.0707070707071 Overall accuracy 0.426\n",
      "0.0808080808081 Overall accuracy 0.424\n",
      "0.0909090909091 Overall accuracy 0.426\n",
      "0.10101010101 Overall accuracy 0.424\n",
      "0.111111111111 Overall accuracy 0.422\n",
      "0.121212121212 Overall accuracy 0.42\n",
      "0.131313131313 Overall accuracy 0.416\n",
      "0.141414141414 Overall accuracy 0.418\n",
      "0.151515151515 Overall accuracy 0.422\n",
      "0.161616161616 Overall accuracy 0.418\n",
      "0.171717171717 Overall accuracy 0.42\n",
      "0.181818181818 Overall accuracy 0.418\n",
      "0.191919191919 Overall accuracy 0.422\n",
      "0.20202020202 Overall accuracy 0.416\n",
      "0.212121212121 Overall accuracy 0.412\n",
      "0.222222222222 Overall accuracy 0.41\n",
      "0.232323232323 Overall accuracy 0.41\n",
      "0.242424242424 Overall accuracy 0.408\n",
      "0.252525252525 Overall accuracy 0.408\n",
      "0.262626262626 Overall accuracy 0.408\n",
      "0.272727272727 Overall accuracy 0.408\n",
      "0.282828282828 Overall accuracy 0.408\n",
      "0.292929292929 Overall accuracy 0.406\n",
      "0.30303030303 Overall accuracy 0.406\n",
      "0.313131313131 Overall accuracy 0.406\n",
      "0.323232323232 Overall accuracy 0.408\n",
      "0.333333333333 Overall accuracy 0.408\n",
      "0.343434343434 Overall accuracy 0.406\n",
      "0.353535353535 Overall accuracy 0.406\n",
      "0.363636363636 Overall accuracy 0.41\n",
      "0.373737373737 Overall accuracy 0.41\n",
      "0.383838383838 Overall accuracy 0.408\n",
      "0.393939393939 Overall accuracy 0.414\n",
      "0.40404040404 Overall accuracy 0.414\n",
      "0.414141414141 Overall accuracy 0.416\n",
      "0.424242424242 Overall accuracy 0.416\n",
      "0.434343434343 Overall accuracy 0.416\n",
      "0.444444444444 Overall accuracy 0.414\n",
      "0.454545454545 Overall accuracy 0.414\n",
      "0.464646464646 Overall accuracy 0.414\n",
      "0.474747474747 Overall accuracy 0.412\n",
      "0.484848484848 Overall accuracy 0.414\n",
      "0.494949494949 Overall accuracy 0.414\n",
      "0.505050505051 Overall accuracy 0.41\n",
      "0.515151515152 Overall accuracy 0.41\n",
      "0.525252525253 Overall accuracy 0.41\n",
      "0.535353535354 Overall accuracy 0.412\n",
      "0.545454545455 Overall accuracy 0.41\n",
      "0.555555555556 Overall accuracy 0.41\n",
      "0.565656565657 Overall accuracy 0.412\n",
      "0.575757575758 Overall accuracy 0.412\n",
      "0.585858585859 Overall accuracy 0.412\n",
      "0.59595959596 Overall accuracy 0.412\n",
      "0.606060606061 Overall accuracy 0.414\n",
      "0.616161616162 Overall accuracy 0.412\n",
      "0.626262626263 Overall accuracy 0.412\n",
      "0.636363636364 Overall accuracy 0.412\n",
      "0.646464646465 Overall accuracy 0.414\n",
      "0.656565656566 Overall accuracy 0.412\n",
      "0.666666666667 Overall accuracy 0.412\n",
      "0.676767676768 Overall accuracy 0.41\n",
      "0.686868686869 Overall accuracy 0.412\n",
      "0.69696969697 Overall accuracy 0.412\n",
      "0.707070707071 Overall accuracy 0.412\n",
      "0.717171717172 Overall accuracy 0.414\n",
      "0.727272727273 Overall accuracy 0.414\n",
      "0.737373737374 Overall accuracy 0.414\n",
      "0.747474747475 Overall accuracy 0.414\n",
      "0.757575757576 Overall accuracy 0.414\n",
      "0.767676767677 Overall accuracy 0.412\n",
      "0.777777777778 Overall accuracy 0.412\n",
      "0.787878787879 Overall accuracy 0.412\n",
      "0.79797979798 Overall accuracy 0.41\n",
      "0.808080808081 Overall accuracy 0.41\n",
      "0.818181818182 Overall accuracy 0.41\n",
      "0.828282828283 Overall accuracy 0.41\n",
      "0.838383838384 Overall accuracy 0.41\n",
      "0.848484848485 Overall accuracy 0.41\n",
      "0.858585858586 Overall accuracy 0.41\n",
      "0.868686868687 Overall accuracy 0.408\n",
      "0.878787878788 Overall accuracy 0.406\n",
      "0.888888888889 Overall accuracy 0.406\n",
      "0.89898989899 Overall accuracy 0.408\n",
      "0.909090909091 Overall accuracy 0.408\n",
      "0.919191919192 Overall accuracy 0.408\n",
      "0.929292929293 Overall accuracy 0.408\n",
      "0.939393939394 Overall accuracy 0.408\n",
      "0.949494949495 Overall accuracy 0.408\n",
      "0.959595959596 Overall accuracy 0.408\n",
      "0.969696969697 Overall accuracy 0.41\n",
      "0.979797979798 Overall accuracy 0.41\n",
      "0.989898989899 Overall accuracy 0.408\n",
      "1.0 Overall accuracy 0.412\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "bx, by = randomize(all_x[idx_valid], all_y[idx_valid], randomize=False)\n",
    "lucene_output = forward_fn(bx)\n",
    "\n",
    "gammas = np.linspace(0, 1, 100)\n",
    "for gamma  in gammas:\n",
    "    overall_output = softmax(lucene_output)*gamma + norm_softmax(W2V[idx_valid])*(1-gamma)\n",
    "    acc = (by.argmax(axis=1) == overall_output.argmax(axis=1)).sum() / by.shape[0]\n",
    "    print(gamma, 'Overall accuracy', acc)\n",
    "    res.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result 0.426 obtained for gamma=0.071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbff512dfd0>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEACAYAAAC08h1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc001ac7690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import *\n",
    "\n",
    "best_acc, best_gamma = max(zip(res, gammas), key=itemgetter(0))\n",
    "print('Best result %.3f obtained for gamma=%.3f' % (best_acc, best_gamma))\n",
    "plot(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 7)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gamma = 0.75\n",
    "\n",
    "bx, by = randomize(all_x, all_y, randomize=False)\n",
    "\n",
    "with open(TRAINING_SET, encoding='utf8') as f_in:\n",
    "    f_in.readline()\n",
    "    with open(join(DATA_DIR, 'analyze_me.tsv'), encoding='utf8', mode='w') as f_out:\n",
    "        print('# answers: lucene\\tw2v\\tcombined', file=f_out)\n",
    "        print(file=f_out)\n",
    "        for i, line in enumerate(f_in):\n",
    "            qid, q, correct, A, B, C, D = line.strip().split('\\t')\n",
    "            x, y = randomize(all_x[i:i+1], all_y[i:i+1], randomize=False)\n",
    "\n",
    "            answer_lucene = softmax(forward_fn(x))\n",
    "            answer_w2v = norm_softmax(W2V[i:i+1])\n",
    "            answer_combined = answer_lucene*gamma + answer_w2v*(1-gamma)\n",
    "            print(qid, correct, sep='\\t', file=f_out)\n",
    "            print(q, file=f_out)\n",
    "            for i, letter, answer_text in zip(xrange(4), 'ABCD', [A, B, C, D]):\n",
    "                print(letter, '%.3f' % answer_lucene[0, i], \n",
    "                      '%.3f' % answer_w2v[0, i], \n",
    "                      '%.3f' % answer_combined[0, i], \n",
    "                      answer_text, sep='\\t', file=f_out)\n",
    "            print(file=f_out)\n",
    "        \n",
    "# lucene_output = softmax(forward_fn(bx))\n",
    "\n",
    "# gamma = 0.222\n",
    "# overall_output = overall_output = softmax(lucene_output)*gamma + norm_softmax(W2V)*(1-gamma)\n",
    "# overall_answers = overall_output.argmax(axis=1)\n",
    "\n",
    "# with open(SUMBISSION_FILE, mode='w') as f:\n",
    "#     print('id,correctAnswer', file=f)\n",
    "#     for i in range(by.shape[0]):\n",
    "#         print(all_qid[i], 'ABCD'[overall_answers[i]], sep=',', file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Submission\n",
    "-----------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gamma = 0.222\n",
    "\n",
    "\n",
    "bx, by = randomize(all_x, all_y, randomize=False)\n",
    "lucene_output = softmax(forward_fn(bx))\n",
    "\n",
    "overall_output = overall_output = softmax(lucene_output)*gamma + norm_softmax(W2V)*(1-gamma)\n",
    "overall_answers = overall_output.argmax(axis=1)\n",
    "\n",
    "with open(SUMBISSION_FILE, mode='w') as f:\n",
    "    print('id,correctAnswer', file=f)\n",
    "    for i in range(by.shape[0]):\n",
    "        print(all_qid[i], 'ABCD'[overall_answers[i]], sep=',', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
